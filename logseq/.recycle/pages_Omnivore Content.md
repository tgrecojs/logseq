- [Zeboot-agenda-Jan-24](https://omnivore.app/me/zeboot-agenda-jan-24-18cfb50c2c2)
  collapsed:: true
  site:: [electriccoin.co](https://electriccoin.co/wp-content/uploads/2024/01/Zeboot-agenda-Jan-24.pdf)
  date-saved:: [[01/11/2024]]
- [Tech/Finance Skill Convergence](https://omnivore.app/me/tech-finance-skill-convergence-18cfa0a0c27)
  collapsed:: true
  site:: [The Diff](https://www.thediff.co/archive/tech-finance-skill-convergence/?ref=the-diff-newsletter)
  author:: Byrne Hobart
  date-saved:: [[01/11/2024]]
  date-published:: [[01/11/2024]]
	- ### Highlights
	  collapsed:: true
		- > (obsessing over latency is useful for cloud computing and for trade execution; being able to tease out tiny signals from huge volumes of data is helpful for systematic investing as well as ad targeting). [⤴️](https://omnivore.app/me/tech-finance-skill-convergence-18cfa0a0c27#410b3433-6b72-47bc-ab30-258378e994b9)
		- > [some Excel products grow to the point that only a single person can understand them, and have to be scrapped when that person leaves](https://www.baseballprospectus.com/news/article/12082/reintroducing-pecota-what-a-long-strange-trip-it-has-been/?ref=thediff.co).
		  > 
		  That last problem isn't intrinsic to Excel, but to programming in general: [⤴️](https://omnivore.app/me/tech-finance-skill-convergence-18cfa0a0c27#974b83e8-a06c-47d5-b02f-e8820b3a10e1)
		- > Scrutability Frontier [⤴️](https://omnivore.app/me/tech-finance-skill-convergence-18cfa0a0c27#2d71d6ae-7790-42d8-805e-c30a700a98d3) 
		  
		  note:: In a general sense, 'scrutability' refers to the degree to which something can be investigated or understood, and 'frontier' refers to an advancing edge or boundary of activity or knowledge. Therefore, a "scrutability frontier" could be understood as the boundary at which our understanding or transparency in a system or phenomena ends.
- [The Protocol Seeking Protocol](https://omnivore.app/me/the-protocol-seeking-protocol-18cf7428727)
  collapsed:: true
  site:: [Dan Finlay’s Blog](https://blog.danfinlay.com/protocol-seeking-protocol/)
  author:: Dan Finlay
  date-saved:: [[01/11/2024]]
  date-published:: [[01/10/2024]]
- [How I take Notes: Mastering the Basics - by Nicola Ballotta](https://omnivore.app/me/how-i-take-notes-mastering-the-basics-by-nicola-ballotta-18cf594cd16)
  collapsed:: true
  site:: [The Hybrid Hacker](https://hybridhacker.email/p/how-i-take-notes-mastering-the-basics)
  author:: Nicola Ballotta
  labels:: [[note-taking]] [[hybrid-hacker]]
  date-saved:: [[01/10/2024]]
  date-published:: [[03/09/2023]]
- [Issue 48 – Bitcoin has "no chance" of going to the moon](https://omnivore.app/me/issue-48-bitcoin-has-no-chance-of-going-to-the-moon-18cf2095d8e)
  collapsed:: true
  site:: [Citation Needed](https://citationneeded.news/issue-48/)
  author:: Molly White
  labels:: [[Read-later]]
  date-saved:: [[01/10/2024]]
  date-published:: [[01/09/2024]]
- [Beyond the shouting match: what is a blockchain, really? -- Dustycloud Brainstorms](https://omnivore.app/me/https-dustycloud-org-blog-what-is-a-blockchain-really-18ce2b8f1d9)
  collapsed:: true
  site:: [dustycloud.org](https://dustycloud.org/blog/what-is-a-blockchain-really/)
  date-saved:: [[01/07/2024]]
  date-published:: [[04/23/2021]]
-
- ## All posts
	- [The Protocol Seeking Protocol](https://omnivore.app/me/the-protocol-seeking-protocol-18cf7428727)
	  collapsed:: true
	  site:: [Dan Finlay’s Blog](https://blog.danfinlay.com/protocol-seeking-protocol/)
	  author:: Dan Finlay
	  labels:: [[Personal Growth]] [[processes]]
	  date-saved:: [[01/11/2024]]
	  date-published:: [[01/10/2024]]
		- ### Content
		  collapsed:: true
			- I'd like to share a synthesis of some ideas I've been working on, framed as a framework for the pursuit of protocol hardness.
			  
			  [ ![Dan Finlay](https://proxy-prod.omnivore-image-cache.app/0x0,saytQUS5JZd0DCOZQg7XqAhKQ06z5tdPKeKjQsv4WcnA/https://www.gravatar.com/avatar/6c7f891f517b95fac7f1fec19620d8e0?s=250&r=x&d=mp) ](https://blog.danfinlay.com/author/dan/) 
			  
			  ![The Protocol Seeking Protocol](https://proxy-prod.omnivore-image-cache.app/0x0,siA6zZL8an4-hv5wdK2i20T-tqLJJeZ_YHIQOphmctB4/https://blog.danfinlay.com/content/images/size/w1200/2024/01/seeking-hardness.png) 
			  
			  How do we decide what's worth building on? How do we ensure the systems we build stay adaptable?
			  
			  As my contribution to "[Onchain: A Farcaster experiment in long-form content](https://warpcast.com/phil/0xb16a35ad?ref=blog.danfinlay.com)", I made a commitment to write some thoughts on a topic I'd wanted to, and for that commitment, I said I wanted to write about a protocol for finding protocols. I had in mind [the Summer of Protocols](https://summerofprotocols.com/?ref=blog.danfinlay.com) work, which has been some of my favorite blogging lately, and especially [the Search for Hardness](https://studio.ribbonfarm.com/p/in-search-of-hardness?ref=blog.danfinlay.com), and its inspiration, [Atoms, Institutions, Blockchains](https://stark.mirror.xyz/n2UpRqwdf7yjuiPKVICPpGoUNeDhlWxGqjulrlpyYi0?ref=blog.danfinlay.com).
			  
			  When I read those articles, I started to see [some of my own work](https://medium.com/capabul?ref=blog.danfinlay.com) in a new light, and particularly I started to see the relationship between a few concepts come together in a more clear way than they had before, and so I'd like to try re-articulating this idea with you, with this fresh frame.
			  
			  Some readers might hope that I would blog a bit on the current state of MetaMask, and where we're [heading](https://snaps.metamask.io/?ref=blog.danfinlay.com). In a way, this article will do that, but by discussing the fundamental issues at a deeper level than a current review of the state of the art.
			  
			  As a brief summary of my understanding of [hardness](https://stark.mirror.xyz/n2UpRqwdf7yjuiPKVICPpGoUNeDhlWxGqjulrlpyYi0?ref=blog.danfinlay.com) & [protocols](https://studio.ribbonfarm.com/p/in-search-of-hardness?ref=blog.danfinlay.com) as those articles describe: Josh Stark has noticed that blockchain rooted value seems to have helped put a sort of light on a certain social concept that he calls "hardness", which would be something like the reliable parts of society that one can build on and ideally take for granted. Venkatesh Rao in his following article then suggests that the study of protocols is the study of the kind of hardness that Stark describes.
			  
			  I'd like to share a synthesis of some ideas I've been working on, and frame it as a generalized set of protocol tools for the pursuit of hardness (not the creation of protocols or hardness itself). I hope you'll find the assumptions and reasoning that builds this model make intuitive sense, and I hope to then take that framework, apply its lens to a few things, and show that despite the compelling and simple logic that it is built with, it has some counterintuitive lessons to teach, including some with significant implications, for example about ideal computer system architectures that don't currently exist.
			  
			  \#\# Moment of Zen, a Dose of Reality
			  
			  Before we continue, here are a couple assumptions that all of this will build on:
			  
			  1. We don't know anything for sure.
			  2. No risk, no reward.
			  
			  You don't know anything: We may discover a new material that seems very hard, but it might be able to take only one gram more. A new longevity protocol is only proven to keep people alive as long as it has so far. You could be in a simulation after all, yadda yadda.
			  
			  You can't benefit from an opportunity without taking it. A cutting edge longevity drug won't keep you alive if you don't take it, but it could poison you. You can't win the lottery without a ticket. You can't make a new friend without meeting a stranger (who might be a murderous stalker). Each of these is just one simple positive result, with a possible risk that might come with it.
			  
			  What does this have to do with protocols, and hardness? Protocols rely on hardness to operate, but finding new sources of hardness is itself a risky endeavor: Trying a new system risks that it fails under your conditions. We may call Bitcoin hard now, but for its first several years, most people wouldn't have even known how to evaluate that claim. We can't have reliable protocols for _any_ purpose unless we can establish paths of credible hardness, and any new source of hardness that could be a opportunity itself introduces new risk. So the pursuit of hardness is like the process of mining risk for reward. Protocols can then be built on top of those new sources of hardness, and just maybe provide some hardness for others to build on.
			  
			  ![](https://proxy-prod.omnivore-image-cache.app/1024x1024,s42I1G3N8Gfw7liyssfesRIHzHBm4W-ibv9TuxYfdaYw/https://blog.danfinlay.com/content/images/2024/01/dwarves.png)
			  
			  When trying to build social arrangements, the same thing applies. We are seeking hardness, but let's not lose touch with the reality that no matter how many fail-safes and layers of safety we add, we are that many failures plus one away from the hardness letting us down.
			  
			  The same applies to digital systems: We are seeking reliability, but while we can add cryptography and resilience, we depend on a software and hardware supply chain and human reviews of the protocols proving properties that mere mortals selected. The most carefully crafted digital system is still riddled with opportunities for surprise.
			  
			  \#\# Taking Baby Steps
			  
			  I'll use "baby step" as a term for the kind of cautious, tenuous stepping I'm portrayed taking in the cover image (yes, I photoshopped it myself, because I was unable to prompt an AI to give me what I had in mind).
			  
			  Baby steps are size invariant: Babies take careful steps, but multinational corporations also make cautious seed investments in unproven technologies that they hope will enable new foundations for their business. They also apply to choosing a software stack, or a protocol to operate an organization on, and so as promised, even protocol selection is prone to this protocol.
			  
			  Baby steps are transitive: As you choose to depend on a system, you inherit all the hardness it rests on. It's risks all the way down to the ground, and who knows what _it_ rests on.
			  
			  ![Guatemala Sinkhole Created by Humans, Not Nature](https://proxy-prod.omnivore-image-cache.app/0x0,sMGl6-TQaloaUCtQuStAMfNMlSprxSj4_jWpZ5WY7zEI/https://i.natgeofe.com/n/940284e5-c4e8-4512-8092-b8569d1de7ed/giant-sinkhole-guatemala-city-why_21263_990x742_square.jpg)
			  
			  A massive sinkhole in Guatemala
			  
			  This fundamental transitivity property is important: When you walk on the street you don't get to say "except if there's a sinkhole under it". When you share an email you don't get to say "but you can't share it" (sorry, DRM advocates)! It's just a law of nature. If we accept the fundamental transitivity of trust and risk, we can save time fighting against reality, and we might just find some valuable ways of improving our own protocols as well.
			  
			  When you take the size-invariance and transitivity of baby steps together, this means baby steps are a good candidate for inductive, graph-theory type proofs: A step is always about an agent moving between two positions, and so an arbitrarily large graph can be reduced to that transitional node pair.
			  
			  To demonstrate how baby steps are friendly to inductive proofs, consider this proof that baby steps advance forward:
			  
			  1. Base Case: A baby can stand stably
			  2. Inductive step: A stably standing baby can very carefully extend its foot to ground _that seems safe_, and transfer its weight to the new foot, finding a new stable standing position.
			  
			  Since a stable standing baby can take a step that leaves them standing stably, this forms an inductive proof that can imply an indefinitely long walk. That is, within the bounds that _each step was up to the baby's judgment to take_. You can't teach a kid to walk without having the chance to fall. Each step is a risk, too.
			  
			  Hence the cautious step style: The baby step game is about how to make the most progress without taking the wrong risk.
			  
			  This gives us the base elements of pursuing hardness:
			  
			  * Accept you will be engaged in minimizing risk for pursuing new rewards.
			  * Minimize the risk of exploring new opportunities, so you can explore more opportunities.
			  * Accept that trust and risk are transitive.
			  
			  There are countless ways of limiting risk, but I'll just describe three broad categories that many things seem to fit in: **Reduction, Revocation, & Recommendation**. Hey, three Rs! Maybe that'll stick!
			  
			  **Reduction** (also known as _attenuation_) means making smaller, more calculated risks. What does it cost to validate an idea, or test a theory? How can you bring that cost down? Using PayPal or Apple Pay instead of entering your credit card into each new website makes it safer to interact with more third party sites. A valet key only lets the driver park the car, not into the trunk or glove box (where you might keep valuables). Is there a circuit breaker on this outlet? A key card on a schedule?
			  
			  **Revocation** means being able to take back a decision. Ideally quickly and responsively. If you subscribed to a bad subscription box, how hard is it to cancel? If you elected a corrupt politician, what is the cost to reverse the result? Can you unplug the device if it sets on fire? Can you reverse the transaction?
			  
			  **Recommendation** is whether someone you trust endorses the thing. Also known as "vouching". Did a friend say this works well? Endorsements are _such_ a sound foundation for taking risks that you can skip the middle-man, and just hand money to a friend. As long as they value your relationship more than the amount at risk, [you're _provably safe_](https://www.socialcollateral.org/papers/Files/SocialCollateral/socialcollateral.pdf?ref=blog.danfinlay.com). This can be dangerous if misused (like trusting strangers that don't have any incentive for your well-being), but can also be extremely powerful.
			  
			  \#\# Scaling Risk Taking: Delegation
			  
			  If taking recommendations is so safe that we can literally hand money to a friend, you might already notice that every kind of risk taking also has similarities to delegation. In some ways, delegation is just a word for relying on something else, and is no different from any other kind of reliance or risk taking.
			  
			  However, I want to establish a slight distinction for my definition of delegation: A delegation is a nonexclusive ability to consume a resource. A few examples would be two people with keys to the same car. Two people on the same bank account. Two people with push rights to the same git remote. When you delegate someone the right to do something, you do not _necessarily_ lose the ability to do it yourself.
			  
			  A delegation may be revoked by either party (equivalent to consuming the resource yourself, or driving off with the car).
			  
			  In web3, the most common type of delegation is the token allowance, which has become the most common way to connect a wallet to an application in a functional way (besides just "proving you hold this key"). It is the foundation of performing any swap, trade, wrap, or bridge. None of those functionalities can perform their roles without access to some funds, and so there will always be a mechanism for some risk to be taken. A way of Reducing that risk further would be to grant allowances with outcomes that are expected (simulation) or enforced ("[offer safety](https://docs.agoric.com/guides/zoe/offer-safety.html?ref=blog.danfinlay.com)", or "[intents](https://www.paradigm.xyz/2023/06/intents?ref=blog.danfinlay.com)").
			  
			  The key insight of delegation is that by being non-exclusive, it expands the number of agents capable of providing the service. As before, the safety proof relies on expanding the risk only to trustworthy agents, but given that assumption, delegation shares burden, can add resilience, and has a potential for adding minimal risk.
			  
			  The top objection I get when advocating delegation as a major fundamental tool for expanding the ability to take risks is from people who think they can reduce risk by reducing how widely a recipient of some capability can share it. That's why I established early in this essay that trust is inherently transitive, and that if we can give up fighting against it, we can yield some benefits. This is a concrete benefit that we can strive for in our systems, if we can just stop fighting against it.
			  
			  A very accessible metaphor for the deep power of delegation is [email](https://www.hpl.hp.com/techreports/2009/HPL-2009-169.pdf?ref=blog.danfinlay.com). It's well established at this point that "information wants to be free", and that's a property of how inherently sharable information is: You can trivially copy some information and share it with someone else. You can share your family's secret recipe, and the other person now has the **power**to create that recipe. They can cover for you at a potluck, but they could also dilute your recipe's value by publishing it online, or taking it to mass production.
			  
			  How about those three Rs? While you can Reduce (redact) a message you send to someone, and you can Recommend they read it (retweet/sharing links), you can't Revoke a message you've shared. Information just happens to be irrevocable. Not all the tools can be used in all contexts, but it's nice to review how many apply :).
			  
			  Information can also convey hard power: A map to a treasure chest, a credit card number, even a gift card or IOU note all have varying degrees of social hardness, but because these pieces of information are signifiers, informing the holder of how to redeem a different (hard) power, those powers become inherently revocable (provided they point at an excludable resource).
			  
			  Since delegation provides a tool for more broadly spreading opportunity-taking risk while also being a tool for taking selective and minimized risk, mechanisms for ensuring delegations can be optimally spread should be of the interest to those seeking good protocols: You can find a suitable sub-component for your protocol faster if you can [employ more hands](https://en.wikipedia.org/wiki/DARPA%5FNetwork%5FChallenge?ref=blog.danfinlay.com) in the search. Your baby step can find its footing faster with more toes, perhaps.
			  
			  One valuable ingredient in allowing a delegation to spread effectively is whether it can travel over multiple hops of a network, and whether it can retain the three Rs as it does it. We can call this property transitivity, or maybe a fourth R: Recursion. By allowing a delegation to flow over many hops, we can invite an even longer network still to help us find our footing. It turns out this constraint is non-trivial, and [the modern dominant mode of computer security (the Access Control List) fails and creates vulnerabilities](https://www.hpl.hp.com/techreports/2009/HPL-2009-20.pdf?ref=blog.danfinlay.com) when pushed in this dimension. To me, this is a huge blaring siren, and I hope even reading this far you might conclude that if what I've said here is true, that this is an imperative: **If we want computers that can help us seek better protocols as effectively as possible, and modern computer architecture isn't well suited to optimal protocol discovery, then we should create one that is. (**[**And**](https://metamask.io/snaps/?ref=blog.danfinlay.com)[**many**](https://delegatable.org/?ref=blog.danfinlay.com)[**of**](https://fission.codes/blog/auth-without-backend/?ref=blog.danfinlay.com)[**us**](https://metamask.io/news/developers/metamask-grants-dao-funds-agoric-and-safeheron-with-first-round-of-grants/?ref=blog.danfinlay.com)[**are**](https://metamask.io/news/developers/metamask-grants-dao-funds-spritely-foundation/?ref=blog.danfinlay.com)**).**
			  
			  \#\# Taking Risks Has a Complementary Dual: Offering Support
			  
			  Whether or not both sides are intelligent, finding support and footing is a two-sided affair. A bridge has two sides, and in most commerce transactions, there is a bidirectional flow of something (even just funds for research, in the case of a grant).
			  
			  This is nicely visible in the case of an exchange's market book: Alice offering to buy Trinkets for Buckaroos is ideally matched with Bob, looking to sell his Trinkets for Buckaroos. Each one is ideally looking for [the ideal protocol](https://link.springer.com/chapter/10.1007/11596370%5F3?ref=blog.danfinlay.com) for sourcing the other, and you know what would be even better than finding a buyer for this one deal? Finding deep, continuous liquidity available for the gifts you have abundant.
			  
			  ![Lichtenberg Epoxy Table | Lichtenberg burning - YouTube](https://proxy-prod.omnivore-image-cache.app/0x0,s2gD_eQEU7G4SwAkH-fSzgEMzFJcx3FpCEhBict-qFJU/https://i.ytimg.com/vi/WRNJUxY-ZC0/maxresdefault.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-HYAC8BCKAgwIABABGGUgUSg9MA8=&rs=AOn4CLChQBnbO9GNVa-amKqdIi5fi0a-lg)
			  
			  A [Lichtenberg](https://www.youtube.com/watch?v=WRNJUxY-ZC0&ref=blog.danfinlay.com) burning. I love these things. You get to tangibly see how electricity flows. It's like, a metaphor, y'know? One side powered by the increased conductivity that comes from the wood in its path having negative ionization. The other powered by the increased conductivity that comes from the wood in its path having positive ionization. Once the two ends meet, the char will carve a highly conductive carbon path which will allow electrons to flow very quickly.
			  
			  \#\# Maximum Liquidity: Cycles
			  
			  I want to take a brief detour and make a nod to the work on "economic cycles" that [has been advocated for](https://twitter.com/buchmanster/status/1558642981518942209?ref=blog.danfinlay.com) by Ethan Buchman, co-founder of Cosmos (briefly touched on in [this podcast](https://podcasts.apple.com/us/podcast/the-wolf-of-all-streets/id1500066831?i=1000622814838&ref=blog.danfinlay.com), too).
			  
			  Let me lay out a series of protocols that follow the above properties, but with increasing nuance and effectiveness. It will culminate in what I think Ethan is getting at:
			  
			  1. A simple order book: You post something you have and something you want, and hope someone takes the deal.
			  2. Two sided order book: Two people can post offers, and someone else can notice the opportunity, capture some arbitrage, and so there is incentive to help match-make.
			  3. Two sided order book with multi-hop incentives: You offer a commission to help you find a deal, and a person is able to take a commission even when sharing the opportunity with others, creating a multi-level incentive system.
			  4. Streaming two-sided order book: If you have a recurring need, and a recurring access to a resource (perhaps a token representing your own goods or services, or a streaming payroll), you could offer a continuous offer, and so have the foundations for continuously automatically shopping for the lowest priced resources that meet your offer criteria.
			  5. Given both 3 and 4, you could find yourself with a sprawling graph of agents helping relay your offer with varying commissions and exchange rates, with the potential for a nearly-mythical ideal case where the graph could help discover **_cycles of mutual benefit_**, allowing tensions to unwind and enable something like a motor of liquidity.
			  
			  A minimum example of a cycle being discovered would be a cobbler and a cowboy: The cobbler needs leather, the cowboy needs shoes. They each discover their existing rate of need, and so due to their standing demands and willingness to have advances of the others' resource, they're each able to tap into that continuous demand as liquidity that can potentially help them fund other needs as well.
			  
			  The way animals and plants breathe each others' exhaust is a cycle in our natural world. 
			  
			  If we apply this lens to protocol design, I would expect that finding closed loops in your protocol's resource consumption could help facilitate the sustainability of that protocol/source of hardness.
			  
			  \#\# The Role of Blockchains
			  
			  While information naturally has many of the properties that we want from a protocol seeking protocol, the ability to revoke access requires additional solutions.
			  
			  I think this is one way of describing the value of blockchains. While Napster and BitTorrent were abundantly capable of allowing information to be shared, there was still no open digital tool that could allow a protocol like money to be built, since the sender of money needs to lose access to it. I don’t remember where I first read this observation, but I think it’s really insightful, please let me know if you find the first person to make this observation that blockchains are good for ensuring someone loses value.
			  
			  A money program written on traditional web2 infrastructure means whoever runs the server controls the ledger, can censor, and even potentially mint money. Anyone can write a program that allows revoking access to a resource, but what if you want to revoke access from the person whose computer runs the program?
			  
			  By introducing a wider pool of rule validators, we can define autonomous protocols where anyone can be more credibly prone to the same rules, since it’s much less feasible to get an influential position over the network. So, blockchains represent a tool-chain for credibly distributing the logic by which someone loses a digital right (by transfer away or other means).
			  
			  \#\# The Shortcomings of Crypto Today
			  
			  While blockchains have enabled the a greatly decentralized possibility of revocation into our digital tool-chain, they've introduced their own shortcomings to the design space, and I think this is where my story begins to turn prescriptive.
			  
			  While blockchain gave us a credible way to _revoke_ access to an information-based technology, two of our Rs took a hit: **Reduction**, and **Recursion** (I'll put aside Recommendation, as existing out of band, for now). Let's consider a modern Ethereum app today.
			  
			  First, let's consider ways where **Reduction** is being inadequately enabled:
			  
			  1. When connecting and signing into a site, users have a hard quantity of permissions that are always initiated first (disclosure of financial history, which [can lead to significant additional risk](https://app.streameth.org/devconnect/wallet%5Funconference/session/decoding%5Fthe%5Fenigma%5Fa%5Fmodel%5Ffor%5Ftransaction%5Fsafety?ref=blog.danfinlay.com)).
			  2. Most dapp interactions start with granting an allowance for the application to operate with those funds, but we don't currently have tooling that enables setting additional boundaries on how the permitted sum is used. Transaction simulation has become popular as a patch to this problem, but it still only provides expected results, and doesn't provide guaranteed boundaries on outcomes, a distinction that I think may become increasingly relevant as simulation becomes common enough that phishers learn to account for it in their strategies.
			  
			  What about Recursion? What might it offer here?
			  
			  1. Cold wallets being able to issue permissions to hot wallets, which could then grant permissions.
			  2. Session keys could allow a dapp to receive some permissions, which it might share with multiple additional services.
			  3. Fund managers acting on your behalf might have limited permission, and represent a form of recommendation within a recursion architecture.
			  
			  Currently there is no toolchain in the Ethereum ecosystem for either reduction or recursion, although we've been working on one:
			  
			  This isn't just an Ethereum problem. Most modern software does not allow you to delegate an arbitrarily attenuated set of permissions to an arbitrary recursive graph of delegates. As soon as you want to invite someone a second hop, you either have to be an admin, or share a password, or invite someone as a peer (at which point they have all the same permissions as you, in which case you're now vulnerable to them).
			  
			  When software runs the world's protocols, the architecture of that software's policy and extensibility defines the flexibility of the world. That's why I think honing in on these essential characteristics of collaborative and dynamic software is one of the highest leverage areas of research in the world right now. It doesn't even have to be complicated! The KeyKOS operating system (the original microkernel) is defined in [just eight pages](https://pdos.csail.mit.edu/6.828/2008/readings/keykos-osr.pdf?ref=blog.danfinlay.com), and has all the properties I've described (except that it deals only with local permissions, not the kind of fully distributed protocol we're talking about building a society on).
			  
			  The most people I've found trying to build software adhering to the principles I've just outlined are doing so under the label of [object capability security](https://en.wikipedia.org/wiki/Object-capability%5Fmodel?ref=blog.danfinlay.com). Don't let the arcane language discourage you: This is the fight for computers that live up to their potential for enabling the dynamic protocols that we need.
			  
			  \#\# Conclusion
			  
			  Where are the sources of hardness that are worthy of building your life's protocols on? You may have to go searching far for them, digging deep in advanced academic literature, or maybe some of them are in your own backyard, or offered with the friendly hand of a neighbor.
			  
			  The quest for hardness is a quest that each of us will endure in our own lives, but because we can build on each others' shoulders, we don't have to wage this quest alone. As long as our protocols for sourcing hardness allow us to choose for ourselves, reduce our risk, revoke mistakes, recommend successes, and recursively join forces, we can create a web of agents that have a natural incentive to collaboratively seek the kinds of hardness that we find acceptable from each other.
			  
			  So let's seek out new foundations for our protocols, and keep in mind what it means to keep our protocols adaptive to new foundations.
			  
			  \#\#\# Further Readings:
			  
			  * [Atoms, Institutions, & Blockchains](https://stark.mirror.xyz/n2UpRqwdf7yjuiPKVICPpGoUNeDhlWxGqjulrlpyYi0?ref=blog.danfinlay.com). Stark. 2023
			  * [Trust and Social Collateral](https://www.socialcollateral.org/papers/Files/SocialCollateral/socialcollateral.pdf?ref=blog.danfinlay.com). Karlan, Mobius, Rosenblat, Szeidl 2008.
			  * [Rich Sharing for the Web](https://www.hpl.hp.com/techreports/2009/HPL-2009-169.pdf?ref=blog.danfinlay.com). Marc Stiegler. 2009
			  * [DARPA Network Challenge](https://en.wikipedia.org/wiki/DARPA%5FNetwork%5FChallenge?ref=blog.danfinlay.com). Wikipedia. Describes an event of 2009.
			  * [ACLs Don't](https://www.hpl.hp.com/techreports/2009/HPL-2009-20.pdf?ref=blog.danfinlay.com). Tyler Close. 2009.
			  * [The Heart of Spritely](https://spritely.institute/static/papers/spritely-core.pdf?ref=blog.danfinlay.com). Webber. 2022
			  * [The KeyKOS Architecture](https://pdos.csail.mit.edu/6.828/2008/readings/keykos-osr.pdf?ref=blog.danfinlay.com). Hardy. 1990
			  * [Towards a Unified Approach to Access Control and Concurrency Control](http://www.erights.org/talks/thesis/markm-thesis.pdf?ref=blog.danfinlay.com). Miller. 2006
			  * [The History of Actors](https://eighty-twenty.org/2016/10/18/actors-hopl?ref=blog.danfinlay.com). Jones. 2016
			  
			  You can collect this blog post's title art as a free NFT for a limited time [on Zora](https://zora.co/collect/oeth:0x46de5c10a47c8cc98499c6bdda3e40e9375b2c62/1?ref=blog.danfinlay.com).
			  
			  \#\# Read more
	- [Beyond the shouting match: what is a blockchain, really? -- Dustycloud Brainstorms](https://omnivore.app/me/https-dustycloud-org-blog-what-is-a-blockchain-really-18ce2b8f1d9)
	  collapsed:: true
	  site:: [dustycloud.org](https://dustycloud.org/blog/what-is-a-blockchain-really/)
	  labels:: [[blockchain]] [[dustycloud]] [[platinum-resource]]
	  date-saved:: [[01/07/2024]]
	  date-published:: [[04/23/2021]]
		- ### Content
		  collapsed:: true
			- \#\# [Beyond the shouting match: what is a blockchain, really?](\#f)
			  
			  By Christine Lemmer-Webber on 
			  
			  If there's one thing that's true about the word "blockchain", it's that these days people have strong opinions about it. Open your social media feed and you'll see people either heaping praises on blockchains, calling them the saviors of humanity, or condemning them as destroying and burning down the planet and making the rich richer and the poor poorer and generally all the other kinds of fights that people like to have about capitalism (also a quasi-vague word occupying some hotly contested mental real estate).
			  
			  There are good reasons to hold opinions about various aspects of what are called "blockchains", and I too have some pretty strong opinions I'll be getting into in a followup article. The followup article will be about "cryptocurrencies", which many people also seem to think of as synonymous with "blockchains", but this isn't particularly true either, but we'll deal with that one then.
			  
			  In the meanwhile, some of the fighting on the internet is kind of confusing, but even more importantly, kind of confused. Some of it might be what I call "sportsballing": for whatever reason, for or against blockchains has become part of your local sportsball team, and we've all got to be team players or we're gonna let the local team down already, right? And the thing about sportsballing is that it's kind of arbitrary and it kind of isn't, because you might pick a sportsball team because you did all your research or you might have picked it because that just happens to be the team in your area or the team your friends like, but god almighty once you've picked your sportsball team let's actually not talk against it because that might be giving in to the other side. But sportsballing kind of _isn't_ arbitrary either because it tends to be initially connected to real communities of real human beings and there's usually a deeper cultural web than appears at surface level, so when you're poking at it, it appears surface-level shallow but there are some real intricacies beneath the surface. (But anyway, go sportsball team.)
			  
			  But I digress. There are important issues to discuss, yet people aren't really discussing them, partly because _people mean different things_. "Blockchain" is a strange term that encompasses a wide idea space, and what people consider or assume essential to it vary just as widely, and thus when two people are arguing they might not even be arguing about the same thing. So let's get to unpacking.
			  
			  \#\# "Blockchain" as handwaving towards decentralized networks in general
			  
			  Years ago I was at a conference about decentralized networked technology, and I was having a conversation with someone I had just met. This person was telling me how excited they were about blockchains... finally we have decentralized network designs, and so this seems really useful for society!
			  
			  I paused for a moment and said yes, blockchains can be useful for some things, though they tend to have significant costs or at least tradeoffs. It's good that we also have other decentralized network technology; for example, the [ActivityPub](https://www.w3.org/TR/activitypub/)standard I was involved in had no blockchains but did rely on the much older "classic actor model."
			  
			  "Oh," the other person said, "I didn't know there were other kinds of decentralized network designs. I thought that 'blockchain' just meant 'decentralized network technology'."
			  
			  It was as if a light had turned on and illuminated the room for me. Oh! This explained so many conversations I had been having over the years. Of course... for many people, blockchains like Bitcoin were the first ever exposure they had (aside from email, which maybe they never gave much thought to as being decentralized) of something that involved a decentralized protocol. So for many people, "blockchain" and "decentralized technology" are synonyms, if not in technical design, but in terms of understanding of a space.
			  
			  Mark S. Miller, who was standing next to me, smiled and gave a very interesting followup: "There is only one case in which you need a blockchain, and that is in a decentralized system which needs to converge on a single order of events, such as a public ledger dealing with the[double spending problem](https://en.wikipedia.org/wiki/Double-spending\#Decentralized%5Fcurrencies)."
			  
			  Two revelations at once. It was a good conversation... it was a good start. But I think there's more.
			  
			  \#\# Blockchains are the "cloud" of merkle trees
			  
			  As time has gone on, the discourse over blockchains has gotten more dramatic. This is partly because what a "blockchain" is hasn't been well defined.
			  
			  All terminology exists on an ever-present battle between[fuzziness and crispness](https://fossandcrafts.org/episodes/23-nerdout-fuzzy-and-crisp.html), with some terms being much clearer than others. The term "boolean" has a fairly crisp definition in computer science, but if I ask you to show me your "stove", the device you show me today may be incomprehensible to someone's definition a few centuries ago, particularly in that today it might not involve fire. Trying to define as in terms of its functionality can also cause confusion: if I asked you to show me a stove, and you showed me a computer processor or a car engine, I might be fairly confused, even though technically people enjoy showing off that they can cook eggs on both of these devices when they get hot enough. (See also: [Identity is a Katamari, language is a Katamari explosion](https://dustycloud.org/blog/identity-is-a-katamari/).)
			  
			  Still, some terms are fuzzier than others, and as far as terms go, "blockchain" is quite fuzzy. Hence my joke: "Blockchains are the 'cloud' of merkle trees."
			  
			  This \~joke tends to get a lot of laughs out of a particular kind of audience, and confused looks from others, so let me explain. The one thing everyone seems to agree on is that it's a "chain of blocks", but all that really seems to mean is that it's a[merkle tree](https://en.wikipedia.org/wiki/Merkle%5Ftree)... really, just an immutable datastructure where one node points at the parent node which points at the parent node all the way up. The joke then is not that this merkle tree runs _on_ a cloud, but that "cloud computing" means approximately nothing: it's marketing speak for some vague handwavey set of "other peoples' computers are doing computation somewhere, possibly on your behalf sometimes." Therefore, "cloud of merkle trees" refers to the vagueness of the situation. (As everyone knows, jokes are funnier when fully explained, so I'll turn on my "STUDIO LAUGHTER" sign here.)
			  
			  So, a blockchain is a chain of blocks, ie a merkle tree, and I mean, technically speaking, that means that [Git](https://git-scm.com/) is a blockchain (especially if the commits are signed), but when you see someone arguing on the internet about whether or not blockchains are "good" or "bad", they probably weren't thinking about git, which aside from having a high barrier of entry in its interface and some concerns about the hashing algorithm used, isn't really something likely to drag you into an internet flamewar.
			  
			  \#\# "Blockchain" is to "Bitcoin" what "Roguelike" is to "Rogue"
			  
			  These days it's common to see people either heaping praises on blockchains or criticizing them, and those people tend to be shouting past one another. I'll save unpacking that for another post. In the meanwhile though, it's worth noting that people might not be talking about the same things.
			  
			  What isn't in doubt is whether or not[Bitcoin](https://en.wikipedia.org/wiki/Bitcoin)is a blockchain... trying to understand and then explore the problem space around Bitcoin is what _created_ the term "blockchain". It's a bit like the video game genre of[roguelikes](https://en.wikipedia.org/wiki/Roguelike), which started with the game[Rogue](https://en.wikipedia.org/wiki/Rogue%5F%28video%5Fgame%29), particularly explored and expanded upon in[NetHack](https://en.wikipedia.org/wiki/NetHack), and then suddenly exploding into the indie game scene as a "genre" of its own. Except the genre has become fuzzier and fuzzier as people have explored the surrounding space. What is essential? Is a grid based layout essential? Is a [non-euclidean grid](http://roguetemple.com/z/hyper/) acceptable? Do you have to provide an ascii or ansi art interface so people can play in their terminals? Dare we allow unicode characters? What if we throw out terminals altogether and just play on a grid of 2d pixelart? What about 3d art? What about permadeath? What about the fantasy theme? What about random level generation? What are the [key features](https://en.wikipedia.org/wiki/Roguelike\#Key%5Ffeatures)of a roguelike?
			  
			  Well now we're at the point where I pick up a game like[Blazing Beaks](https://blazingbeaks.fandom.com/wiki/Blazing%5FBeaks%5FWiki)and it calls itself a["roguelite"](https://en.wikipedia.org/wiki/Roguelike\#Rogue-lites%5Fand%5Fprocedural%5Fdeath%5Flabyrinths), which I guess is embracing the point that terminology has gotten extremely fuzzy... this game feels more like[Robotron](https://en.wikipedia.org/wiki/Robotron)than [Rogue](https://en.wikipedia.org/wiki/Rogue%5F%28video%5Fgame%29).
			  
			  So... if "blockchain" is to Bitcoin what "roguelike" is to Rogue, then what's essential to a blockchain? Does the blockchain have to be applied to a financial instrument, or can it be used to store updateable information about eg identity? Is global consensus required? Or what about a "trusted quorum" of nodes, such as in Hyperledger? Is "mining" some kind of asset a key part of the system? Is proof of work acceptable, or is proof of stake okay? What about proof of space, proof of space-time, proof of pudding?
			  
			  On top of all this, some of the terms _around_ blockchains have been absorbed as if into them. For instance, I think to many people, "smart contract" means something like "code which runs on a blockchain" thanks to Ethereum's major adoption of the term, but the[E programming language](http://www.erights.org/)described "smart contracts" as the "likely killer app of distributed capabilities" all the way[back in 1999](https://web.archive.org/web/19990125095122/http://www.erights.org/), and was[borrowing the term](https://web.archive.org/web/19990209105758/http://www.best.com/%7Eszabo/smart%5Fcontracts%5Fidea.html)from[Nick Szabo](https://web.archive.org/web/19990128165611/http://www.best.com/%7Eszabo/), but really the same folks working on E had described many of those same ideas in the [Agoric Papers](https://agoric.com/papers/) back in 1988\. Bitcoin wasn't even a thing at all until at least 2008, so depending on how you look at it, "smart contracts" precede "blockchains" by one or two decades. So "blockchain" has somehow even rolled up terms _outside_ of its space as if within it. (By the way, I don't think anyone has given a good and crisp definition for "smart contract" either despite some of these people trying to give me one, so let me give you one that I think is better and embraces its fuzziness: "Smart contracts allow you to do the kinds of things you might do with legal contracts, but relying on networked computation instead of a traditional state-based legal system." It's too bad more people also don't know about the huge role that Mark Miller's "split contracts" idea plays into this space because that's what makes the idea finally makes sense... but that's a conversation for another time.) (**EDIT:** Well, after I wrote this, Kate Sills lent me her definition, which I think is the best one: "Smart contracts are credible commitments using technology, and outside a state-provided legal system." I like it!)
			  
			  So anyway, the point of this whole section is to say that kind of like roguelike, people are thinking of different things as essential to blockchains. Everyone roughly agrees on the jumping-off point of ideas but since not everyone agrees from there, it's good to check in when we're having the conversation. Wait, you do/don't like this game because it's a roguelike? Maybe we should check in on what features you mean. Likewise for blockchains. Because if you're blaming blockchains for burning down the planet, more than likely you're not condemning signed git repositories (or at least, if you're condemning them, you're probably doing so about it from an aspect that isn't the fundamental datastructure... probably).
			  
			  This is an "easier said than done" kind of thing though, because of course, I'm kind of getting into some "in the weeds" level of details here... but it's the "in the weeds" where all the substance of the disagreements really are. The person you are talking with might not actually even know or consider the same aspects to be essential that you consider essential though, so taking some time to ask which things we mean can help us lead to a more productive conversation sooner.
			  
			  \#\# "Blockchain" as an identity signal
			  
			  First, a digression. One thing that's kind of curious about the term["virtue signal"](https://en.wikipedia.org/wiki/Virtue%5Fsignaling)is that in general it tends to be used as a kind of virtue signal. It's kind of like the word[hipster](https://en.wikipedia.org/wiki/Hipster%5F%28contemporary%5Fsubculture%29)in the previous decade, which weirdly seemed to be obsessively and pejoratively used by people who resembled hipsters than anyone else. Hence I used to make a joke called "hipster recursion", which is that since hipsters seem more obsessesed with pejorative labeling of hipsterism than anyone else, there's no way to call someone a "hipster" without yourself taking on hipster-like traits, and so inevitably even this conversation is N-levels deep into hipster recursion for some numerical value of N.
			  
			  "Virtue signaling" appears similar, but _even more_ ironically so (which is a pretty amazing feat given how much of hipsterdom seems to surround a kind of inauthentic irony). When I hear someone say "virtue signaling" with a kind of sneer, part of that seems to be acknowledging that other people are sending signals merely to impress others that they are some kind of the same group but it seems as if it's being raised as in a you-know-and-I-know-that-by-me-acknowledging-this-I'm-above-virtue-signaling kind of way. Except that by any possible definition of virtue signaling, the above appears to be a kind of virtue signaling, so now we're into virtue signaling recursion.
			  
			  Well, one way to claw our way out of the rabbithole of all this is to drop the pejorative aspect of it and just acknowledge that signaling is something that everyone does. Hence me saying "identity signaling" here. You can't really escape identity signaling, or even sportsballing, but you can acknowledge that it's a thing that we all do, and there's a reason for it: people only have so much time to find out information about each other, so they're searching for clues that they might align and that, if they introduce you to their peer group, that you might align with them as well, without access to a god-like view of the universe where they know _exactly_ what you think and _exactly_ what kinds of things you've done and _exactly_ what way you'll behave in the future or whether or not you share the same values. (After all, what else is[virtue ethics](https://en.wikipedia.org/wiki/Virtue%5Fethics)but an ethical framework that takes this in its most condensed form as its foundation?) But it's true that at its worst, this seems to result in shallow, quick, judgmental behavior, usually based on stereotypes of the other side... which can be unfortunate or unfair to whomever is being talked about. But also on the flip side, people also do identity signal to each other because they _want_ to create a sense of community and bonding. That's what a lot of culture _is_. It's worth acknowledging then that this occurs, recognizing its use and limitations, without pretending that we are above it.
			  
			  So wow, that's quite a major digression, so now let's get back to "identity signaling". There is definitely a _lot_ of identity signaling that tends to happen around the word "blockchain", for or against. Around the critiques of the worst of this, I tend to agree: I find much of the machismo hyper-white-male-privilege that surrounds some of the "blockchain" space uncomfortable or cringey.
			  
			  But I also have some close friends who are not male and/or are people of color and those ones tend to actually _suffer the worst of it_ from these communities internally, but also seem to find things of value in them, but particularly seem to feel squeezed externally when the field is _reduced to_ these kinds of (anti?-)patterns. There's something sad about that, where I see on the one hand friends complaining about blockchain from the outside on behalf of people who on the inside seem to be both struggling internally but then kind of crushed by being lumped into the same identified problems externally. This is hardly a unique problem but it's worth highlighting for a moment I think.
			  
			  But anyway, I've taken a bunch of time on this, more than I care to, maybe because (irony again?) I feel that too much of public conversation is also hyperfocusing on this aspect... whether there's a subculture around blockchain, whether or not that subculture is good or bad, etc. There's a lot worthwhile in unpacking this discourse-wise, but some of the criticisms of blockchains as a _technology_ (to the extent it even is coherently one) seem to get lumped up into all of this. It's good to provide thoughtful cultural critique, particularly one which encourages healthy social change. And we can't escape identity signaling. But as someone who's trying to figure out what properties of networked systems we do and don't want, I feel like I'm trying to navigate the machine and for whatever reason, my foot keeps getting caught in the gears here. Well, maybe that itself is pointing to some architectural mistakes, but socially architectural ones. But it's useful to also be able to draw boundaries around it so that we know where this part of the conversation begins and ends.
			  
			  \#\# "Blockchain" as "decentralized centralization" (or "decentralized convergence")
			  
			  One of the weird things about people having the idea of "blockchains" as being synonymous with "decentralization" is that it's kind of both very true and very _untrue_, depending on what abstraction layer you're looking at.
			  
			  For a moment, I'm going to frame this in harsh terms: blockchains are decentralized centralization.
			  
			  What? How dare I! You'll notice that this section is in harsh contrast to the "blockchain as handwaving towards decentralized networks in general" section... well, I _am_ acknowledging the decentralized aspect of it, but the weird thing about a blockchain is that it's a decentralized set of nodes _converging on_ (creating a centrality of!) a single abstract machine.
			  
			  Contrast with[classic actor model](https://en.wikipedia.org/wiki/Actor%5Fmodel\#Fundamental%5Fconcepts)systems like[CapTP](http://erights.org/elib/distrib/captp/index.html)in [Spritely Goblins](https://spritelyproject.org/\#goblins), or as less good examples (because they aren't quite as behavior-oriented as they are correspondence-oriented, usually)[ActivityPub](https://www.w3.org/TR/activitypub/)or[SMTP](https://en.wikipedia.org/wiki/Simple%5FMail%5FTransfer%5FProtocol)(ie, email). All of these systems involve decentralized computation and collaboration stemming from sending messages to actors (aka "distributed objects"). Of CapTP this is especially clear and extreme: computations happen in parallel across many collaborating machines (and even better, many collaborating objects on many collaborating machines), and the behavior of other machines and their objects is often even opaque to you. (CapTP survives this in a beautiful way, being able to do well on anonymous, peer to peer, "mutually suspicious" networks. But maybe read my[rambling thoughts about CapTP](https://spritelyproject.org/news/what-is-captp.html)elsewhere.)
			  
			  While to some degree there are some very[clever](https://en.wikipedia.org/wiki/Homomorphic%5Fencryption) [tricks](https://en.wikipedia.org/wiki/Zero-knowledge%5Fproof)in the world of cryptography where you may be able to get back some of the opacity, this tends to be very expensive, adding an expensive component to the already inescapable additional expenses of a blockchain. A multi-party blockchain with some kind of consensus_will always, by definition_ be slower than a single machine operating alone.
			  
			  If you are irritated by this framing: good. It's probably good to be irritated by it at least once, if you can recognize the portion of truth in it. But maybe that needs some unpacking to get there. It might be better to say "blockchains are decentralized _convergence_", but I have some other phrasing that might be helpful.
			  
			  \#\# "Blockchain" as "a single machine that many people run"
			  
			  There's value in having a single abstract machine that many people run. The most famous source of value is in the "double spending problem". How do we make sure that when someone has money, they don't spend that money twice?
			  
			  Traditional accounting solves this with a linear, sequential ledger, and it turns out that the right solution boils down to the same thing in computers. Emphasis on _sequential_: in order to make sure money balances out right, we really do have to be able to order things.
			  
			  Here's the thing though: the double spending problem was in a sense solved in terms of single-computers a long time ago in the object capability security community.[Capability-based Financial Instruments](http://erights.org/elib/capability/ode/index.html)was written about a _decade_ before blockchains even existed and showed off how to make a "mint" (kind of like a fiat-currency bank) that can be implemented in about 25 lines of code in the right architecture (I've [ported it to Goblins](https://gitlab.com/spritely/goblins/-/blob/4f664218c87fa96432a04d0a107618ec36ab9310/goblins/actor-lib/simple-mint.rkt\#L13), for instance) and yet has both distributed accounts and is robust against corruption on errors.
			  
			  However, this seems to be running on a "single-computer based machine", and again operates like a fiat currency. Anyone can create their own fiat currency like this, and they are cheap, cheap, cheap (and fast!) to make. But it does rely on sequentiality to some degree to operate correctly (avoiding a class of attacks called "re-entrancy attacks").
			  
			  But this "single-computer based machine" might bother you for a couple reasons:
			  
			  * We might be afraid the server might crash and service will be interrupted, or worse yet, we will no longer be able to access our accounts.
			  * Or, even if we could trade these on an open market, and maybe diversify our portfolio, maybe we don't want to _have to_ trust a single operator or even some appointed team of operators... maybe we have a lot of money in one of these systems and we want to be sure that it won't suddenly vanish due to corruption.
			  
			  Well, if our code operates deterministically, then what if from the same initial conditions (or saved snapshot of the system) we replay all input messages to the machine? Functional programmers know: we'll end up with the same result.
			  
			  So okay, we might want to be sure this doesn't accidentally get corrupted, maybe for backup reasons. So maybe we submit the input messages to _two_ computers, and then if one crashes, we just continue on with the second one until the other comes up, and then we can restore the first one from the progress the second machine made while the first one was down.
			  
			  Oh hey, this is already technically a blockchain. Except our trust model is that we implicitly trust _both_ machines.
			  
			  Hm. Maybe we're now worried that we might have top-down government pressure to coerce some behavior on one of our nodes, or maybe we're worried that someone at a local datacenter is going to flip some bits to make themselves rich. So we actually want to spread this abstract machine out over three countries. So okay, we do that, and now we set a rule agreeing on what all the series of input messages are... if two of three nodes agree, that's good enough. Oh hey look, we've just invented the "small-quorum-style" blockchain/ledger!
			  
			  (And yes, you can wire up [Goblins](https://docs.racket-lang.org/goblins/index.html)to do just this; a hint as to how is seen in the[Terminal Phase time travel demo](https://dustycloud.org/blog/goblins-time-travel-micropreview/). Actually, let's come back to that later.)
			  
			  Well, okay. This is probably good enough for a private financial asset, but what about if we want to make something more... global? Where nobody is in charge!
			  
			  Well, we could do that too. Here's what we do.
			  
			  * First, we need to prevent a "swarming attack" (okay, this is generally called a "sybil attack" in the literature, but for a multitude of reasons I won't get into, I don't like that term). If a global set of peers are running this single abstract machine, we need to make sure there aren't invocations filling up the system with garbage, since we all basically have to keep that information around. Well... this is exactly where those proof-of-foo systems come in the first time; in fact Proof of Work's origin is in something called [Hashcash](https://en.wikipedia.org/wiki/Hashcash) which was designed to add "friction" to disincentivize spam for email-like systems. If we don't do something friction-oriented in this category, our ledger is going to be too easily filled with garbage too fast. We also need to agree on what the _order_ of messages is, so we can use this mechanism in conjuction with a consensus algorithm.
			  * When are new units of currency issued? Well, in our original mint example, the person who set up the mint was the one given the authority to make new money out of thin air (and they can hand out attenuated versions of that authority to others as they see fit). But what if instead of handing this capability out to _individuals_we handed it out to _anyone who can meet an abstract requirement_? For instance, in [zcap-ld](https://w3c-ccg.github.io/zcap-ld/)an invoker can be any kind of entity which is specified with[linked data proofs](https://w3c-ccg.github.io/ld-proofs/), meaning those entities can be something other than a single key... for instance, what if we delegated to an abstract invoker that was specified as being "whoever can solve the state of the machine's current proof-of-work puzzle"? Oh my gosh! We just took our 25-line mint and extended it for mining-style blockchains. And the fundamental design still applies!
			  
			  With these two adjustments, we've created a "public blockchain" akin to bitcoin. And we don't need to use proof-of-work for either technically... we could swap in different mechanisms of friction / qualification.
			  
			  If the set of inputs are stored as a merkle tree, then all of the system types we just looked at are technically blockchains:
			  
			  * A second machine as failover in a trusted environment
			  * Three semi-trusted machines with small-scale private consensus
			  * A public blockchain without global trust, with swarming-attack resistance and an interesting abstract capability accessible to anyone who can meet the abstract requirement (in this case, to issue some new currency).
			  
			  The difference for choosing any of the above is really a question of: "what is your trust/failover requirements?"
			  
			  \#\# Blockchains as time travel plus convergent inputs
			  
			  If this doesn't sound believable to you, that you could create something like a "public blockchain" on top of something like Goblins so easily, consider how we might extend[time travel in Terminal Phase](https://dustycloud.org/blog/goblins-time-travel-micropreview/)to add multiplayer. As a reminder, here's an image:
			  
			  ![Time travel in Spritely Goblins shown through Terminal Phase](https://proxy-prod.omnivore-image-cache.app/0x0,swPNFWnEaCRYmjVaA--gke61qFDbLiEIQwZXFqnMDiGw/https://dustycloud.org/gfx/goodies/terminal-phase-goblins-time-travel.gif)
			  
			  Now, a secret thing about Terminal Phase is that the gameplay is deterministic (the random starfield in the background is not, but the gameplay is) and runs on a fixed frame-rate. This means that given the same set of keyboard inputs, the game will always play the same, every time.
			  
			  Okay, well let's say we wanted to hand some way for someone to replay our last game. Chess games can be fully replayed with a very[condensed syntax](https://en.wikipedia.org/wiki/Algebraic%5Fnotation%5F%28chess%29), meaning that merely handing someone a short list of codes they can_precisely_ replay the same game, every time, deterministically.
			  
			  Well okay, as a first attempt at thinking this through, what if for some game of Terminal Phase I played we wrote down each keystroke I entered on my keyboard, on every tick of the game? Terminal Phase runs at 30 ticks per second. So okay, if you replay these, each one at 30 ticks per second, then yeah, you'd end up with the same gameplay every time.
			  
			  It would be simple enough for me to encode these as a linked list (cons, cons, cons!) and hand them to you. You could descend all the way to the root of the list and start playing them back up (ie, play the list in reverse order) and you'd get the same result as I did. I could even stream new events to you by giving you new items to tack onto the front of the list, and you could "watch" a game I was playing live.
			  
			  So now imagine that you and I want to play Terminal Phase together now, over the network. Let's imagine there are two ships, and for simplicity, we're playing cooperatively. (The same ideas[can be extended to competitive](https://en.wikipedia.org/wiki/Lockstep%5Fprotocol), but for narrating how real-time games work it's easier to to start with a cooperative assumption.)
			  
			  We could start out by wiring things up on the network so that I am allowed to press certain keys for player 1 and you are allowed to press certain keys for player 2\. (Now it's worth noting that a better way to do this doesn't involve_keys on the keyboard_ but _capability references_, and really that's how we'd do things if we were to bring this multiplayer idea live, but I'm trying to provide a metaphor that's easy to think about without introducing the complicated sounding kinds of terms like "c-lists" and "vat turns" that we ocap people seem to like.) So, as a first attempt, maybe if we were playing on a local area network or something, we could synchronize at every game tick: I share my input with you and you share yours, and then and only then do both of our systems actually input them into that game-tick's inputs. We'll have achieved a kind of "convergence" as to the current game state on every tick. (**EDIT:** I wrote "a kind of _consensus_" instead of "a kind of_convergence_" originally, and that was an error, because it misleads on what consensus algorithms tend to do.)
			  
			  Except this wouldn't work very well if you and I were living far away from each other and playing over the internet... the lag time for doing this for every game tick might slow the system to a crawl... our computers wouldn't get each others' inputs as fast as the game was moving along, and would have to pause until we received each others' moves.
			  
			  So okay, here's what we'll do. Remember the time-travel GUI above? As you can see, we're effectively restoring from an old snapshot. Oh! So okay. We could save a snapshot of the game every second, and then both get each other our inputs to each other as fast as we can, but knowing it'll lag. So, without having seen your inputs yet, I could move my ship up and to the right and fire (and send that I did that to you). My game would be in a "dirty state"... I haven't actually seen what you've done yet. Now suddenly I get the last set of moves you did over the network... in the last five frames, you move down and to the left and fire. Now we've got each others' inputs... what our systems can do is_secretly time travel behind the scenes to the last snapshot_, then_fast forward_, replaying both of our inputs on each tick up until the latest state where we've both seen each others' moves (but we wouldn't_show_ the fast forward process, we'd just show the result with the fast forward having been applied). This can happen fast enough that I might see your ship jump forward a little, and maybe your bullet will kill the enemy instead of mine and the scores shift so that you actually got some points that for a moment I thought I had, but this can all happen in realtime and we don't need to slow down the game at all to do it.
			  
			  Again, all the above can be done, but with actual wiring of capabilities instead of the keystroke metaphor... and actually, the same set of ideas can be done with _any_ kind of system, not just a game.
			  
			  And oh hey, technically, technically, _technically_ if we both hashed each of our previous messages in the linked list and signed each one, then this would qualify as a merkle tree and then this would also qualify as a blockchain... but wait, this doesn't have anything to do with cryptocurrencies! So is it really a blockchain?
			  
			  \#\# "Blockchain" as synonym for "cryptocurrency" but this is wrong and don't do this one
			  
			  By now you've probably gotten the sense that I really was annoyed with the first section of "blockchain" as a synonym for "decentralization" (especially because blockchains are decentralized centralization/convergence) and that is completely true. But even more annoying to me is the synonym of "blockchain" with "cryptocurrency".
			  
			  "Cryptocurrency" means "cryptographically based currency" and it is NOT synonymous with blockchains.[Digicash](https://en.wikipedia.org/wiki/DigiCash) precedes blockchains by a dramatic amount, but it is a cryptocurrency. The "simple mint" type system also precedes blockchains and while it can be run on a blockchain, it can also run on a solo computer/machine.
			  
			  But as we saw, we could perceive multiplayer Terminal Phase as technically, technically a blockchain, even though it has _nothing to do with_currencies whatsoever.
			  
			  So again a blockchain is just a single, abstract, sequential machine, run by multiple parties. That's it. It's more general than cryptocurrencies, and it's not exclusive to implementing them either. One is a kind of programming-plus-cryptography-use-case (cryptocurrencies), the other one is a kind of abstracted machine (blockchains).
			  
			  So please. They are frequently combined, but don't treat them as the same thing.
			  
			  \#\# Blockchains as single abstract machines on a wider network
			  
			  One of my favorite talks is Mark Miller's[Programming Secure Smart Contracts](https://www.youtube.com/watch?v=YXUqfgdDbr8)talk. Admittedly, I like it partly because it well illustrates some of the low-level problems I've been working on, and that might not be as useful to everyone else. But it has this lovely diagram in it:
			  
			  ![Machines / Vats / Ocaps / Erights layers of abstractions](https://proxy-prod.omnivore-image-cache.app/0x0,sR8AfKoMVXf3-JejC7UM-DFFYNAvNoNwsLAXAUZ8kQnQ/https://dustycloud.org/etc/images/blog/markm-agoric-layers.png)
			  
			  This is better understood by watching the video, but the abstraction layers described here are basically as follows:
			  
			  * "Machines" are the lowest layer of abstraction on the network, but there a variety of kinds of machines. Public blockchains are one, quorum blockchains are another, solo computer machines yet another (and the simplest case, too). What's interesting then is that we can see public chains and quorums abstractly demonstrated as machines in and of themselves... even though they are run by many parties.
			  * Vats are the next layer of abstraction, these are basically the "communicating event loops"... actors/objects live inside them, and more or less these things run sequentially.
			  * Replace "JS ocaps" with "language ocaps" and you can see actors/objects in both Javascript and Spritely living here.
			  * Finally, at the top are "erights" and "smart contracts", which feed into each other... "erights" are "exclusive electronic rights", and "smart contracts" are generally patterns of cooperation involving achieving mutual goals despite suspicion, generally involving the trading of these erights things (but not necessarily).
			  
			  Okay, well cool! This finally explains the worldview I see blockchains on. And we can see a few curious things:
			  
			  * The "public chain" and "quorum" kinds of machines still boil down to a single, sequential abstract machine.
			  * Object connections exist between the machines... ocap security. No matter whether it's run by a single computer or multiple.
			  * Public blockchains, quorum blockchains, solo-computer machines all talk to each other, and communicate between object references on each other.
			  
			  Blockchains are not magical things. They are abstracted machines on the network. Some of them have special rules that let whoever can prove they qualify for them access some well-known capabilities, but really they're just abstracted machines.
			  
			  And here's an observation: you aren't ever going to move all computation to a single blockchain. Agoric's CEO, Dean Tribble,[explained beautifully why on a recent podcast](https://youtu.be/WeRbY6tiAio?t=712):
			  
			  > One of the problems with Ethereum is it is as tightly coupled as possible. The entire world is a single sequence of actions that runs on a computer with about the power of a cell phone. Now, that's obviously hugely valuable to be able to do commerce in a high-integrity fashion, even if you can only share a cell phone's worth of compute power with the entire rest of the world. But that's clearly gonna hit a brick wall. And we've done lots of large-scale distributed systems whether payments or cyberspace or coordination, and the fundamental model that covers all of those is_islands of sequential programming in a sea of asynchronous communication_. That is what the internet is about, that's what the interchain is about, that's what _physics_ requires you to do if you want a system to scale.
			  
			  Put this way, it should be obvious: are we going to replace the entire internet with something that has the power of a cell phone? To ask the question is to know the answer: of course not. Even when we do admit blockchain'y systems into our system, we're going to have to have many of them communicating with each other.
			  
			  Blockchains are just machines that many people/agents run. That's it.
			  
			  Some of these are encoded with some nice default programming to do some useful things, but all of them can be done in non-blockchain systems because_communicating islands of sequential processes is the generalization_. You might still want a blockchain, ie you might want multiple parties running one of those machines as a shared abstract machine, but how you configure that blockchain from there might depend on your trust and integrity requirements.
			  
			  \#\# What do I think of blockchains?
			  
			  I've covered a wide variety of perspectives of "what is a blockchain" in this article.
			  
			  On the worse end of things are the parts involving hand-wavey confusion about decentralization, mistaken ideas of them being tied to cryptocurrencies, marketing hype, cultural assumptions, and some real, but not intrinsic, cultural problems.
			  
			  In the middle, I am particularly keen on highlighting the similarity between the term "blockchain" and the term "roguelike", how both of them might boil down to some key ideas or not, but more importantly they're both a rough family of ideas that diverge from one highly influential source (Bitcoin and Rogue respectively). This is also the source of much of the "shouting past each other", because many people are referring to different components that they view as essential or inessential. Many of these pieces may be useful or harmful in isolation, in small amounts, in large amounts, but much of the arguing (and posturing) involves highlighting different things.
			  
			  On the better end of things is a revelation, that blockchains are just another way of abstracting a computer so that multiple parties can run it. The particular decisions and use cases layered on top of this fundamental design are highly variant.
			  
			  Having made the waters clear again, we could muddy them. A friend once tried to convince me that _all_ computers are technically blockchains, that blockchains are the generalization of computing, and the case of a solo computer is merely one where a blockchain is run only by one party and no transaction history or old state is kept around. Maybe, but I don't think this is very useful. You can go in either direction, and I think the time travel and Terminal Phase section maybe makes that clear to me, but I'm not so sure how it lands with others I suppose. But a term tends to be useful in terms of what it _introduces_, and calling everything a blockchain seems to make the term even less useful than it already is. While a blockchain could be one or more parties running a sequential machine as the generalization, I suggest we stick to two or more.
			  
			  Blockchains are not magic pixie dust, putting something on a blockchain does not make it work better or more decentralized... indeed, what a blockchain really does is converging (or re-centralizing) a machine from a decentralized set of computers. And it always does so with some cost, some set of overhead... but what those costs and overhead _are_ varies depending on what the configuration decisions are. Those decisions _should_ always stem from some careful thinking about what those trust and integrity needs are... one of the more frustrating things about blockchains being a technology of great hype and low understanding is that such care is much less common than it should be.
			  
			  Having a blockchain, as a convergent machine, can be useful. But how that abstracted convergent machine is arranged can diverge dramatically; if we aren't talking about the same choices, we might shout past each other. Still, it may be an unfair ask to request that those without a deep technical background go into technical specifics, and I recognize that, and in a sense there can be some amount gained from speaking towards broad-sweeping, fuzzy sets and the patterns they seem to be carrying. A gut-sense assertion from a set of loosely observed behaviors can be a useful starting point. But to get at the root of what those gut senses actually map to, we will have to be specific, and we should encourage that specificity where we can (without being rude about it) and help others see those components as well.
			  
			  But ultimately, as convergent machines, blockchains will not operate alone. I think the system that will hook them all together[should be CapTP](https://spritelyproject.org/news/what-is-captp.html). But no matter the underlying protocol abstraction, blockchains are just abstract machines on the network.
			  
			  Having finally disentangled what _blockchains_ are, I think soon I would like to move onto what _cryptocurrencies_ are. Knowing that they are _not necessarily tied to blockchains_ opens us up to considering an ecosystem, even an interoperable and exchangeable one, of varying cryptographically based financial instruments, and the different roles and uses they might play. But that is another post of its own, for whenever I can get to it, I suppose.
			  
			  **ADDENDUM:** After writing this post, I had several conversations with several blockchain-oriented people. Each of them roughly seemed to agree that Bitcoin was roughly the prototypical "blockchain", but each of them also seemed to highlight different things they thought were "essential" to what a "blockchain" is: some kinds of consensus algorithms being better than others, that kinds of social arrangements are enabled, whether transferrable assets are encoded on the chain, etc. To start with, I feel like this does confirm some of the premise of this post, that Bitcoin is the starting point, but like Rogue and "roguelikes", "blockchains" are an exploration space stemming from a particular influential technical piece.
			  
			  However my friend Kate Sills (who also gave me a much better definition for "smart contracts", added above) highlighted something that I hadn't talked about much in my article so far, which I do agree deserves expansion. Kate said: "I do think there is something huge missing from your piece. Bitcoin is amazing because it aligns incentives among actors who otherwise have no goals in common."
			  
			  I agree that there's something important here, and this definition of "blockchain" maybe does explain why while from a computer science perspective, perhaps signed git trees do resemble blockchains, they don't seem to fit within the realm of what most people are thinking about... while git might be a tool used by several people with aligned incentives, it is not generally itself the layer of incentive-alignment.
	- [bafykbzacebgdv7toazeqnhsuj6ei4zhs2ks4m5wmf6dzqbfi34tmzsd3ai674](https://omnivore.app/me/-18cbe934bac)
	  collapsed:: true
	  site:: [cloudflare-ipfs.com](https://cloudflare-ipfs.com/ipfs/bafykbzacebgdv7toazeqnhsuj6ei4zhs2ks4m5wmf6dzqbfi34tmzsd3ai674?filename=%28Lecture+Notes+in+Computer+Science+11815%29+Klaus-Dieter+Schewe%2C+Neeraj+Kumar+Singh+-+Model+and+Data+Engineering_+9th+International+Conference%2C+MEDI+2019%2C+Toulouse%2C+France%2C+October+28%E2%80%9331%2C+2019%2C+Proceedi%28Z-Lib.io%29.pdf)
	  date-saved:: [[12/31/2023]]
		- ### Content
		  collapsed:: true
			-
	- [Marvelous Merkle Trees | Pangea](https://omnivore.app/me/https-pangea-cloud-docs-blog-marvelous-merkle-trees-18c5794ca03)
	  collapsed:: true
	  site:: [pangea.cloud](https://pangea.cloud/docs/blog/marvelous-merkle-trees)
	  author:: Ian ForrestDirector of Cool Hats
	  date-saved:: [[12/11/2023]]
	  date-published:: [[07/20/2022]]
		- ### Content
		  collapsed:: true
			- ![Photo by Pixabay: https://pixabay.com/photos/trees-wilderness-nature-woods-3822149/](https://proxy-prod.omnivore-image-cache.app/800x400,slSxqyv_J-gh5L8oyNIeN9naHg8FS8kUzu3lADW6-8F8/https://pangea.cloud/docs/assets/images/06BlogBlogCover-fc217d72c8ef42a758248358ea5ef2b0.jpg)
			  
			  In my previous blog post, I wrote about how one might go about building a [Tamperproof Logging Implementation](https://pangea.cloud/docs/blog/a-tamperproof-logging-implementation/). A good-sized chunk of that post was about how one could use Merkle Trees to verify the individual log messages while also verifying the consistency of the entire set of logs. What I didn’t cover is why Merkle Trees were used in the first place.
			  
			  First, a quick refresher on Merkle Trees. A Merkle Tree is implemented as a binary tree where each leaf node is a hash of data. Each intermediate node is a hash of its two immediate children, culminating in a unique root hash at the top of the tree.
			  
			  The result is something that looks like this:
			  
			  The properties of a Merkle Tree allow for the verification of any leaf node’s inclusion in the tree by providing what’s called a Merkle Proof, sometimes referred to as an inclusion proof. A Merkle Proof consists of a leaf node’s sibling and each intermediate hash needed to calculate the root hash. By calculating the root hash with Merkle Proof and comparing it to a published root hash from a trusted location, data can easily be validated for inclusion.
			  
			  ![verifying a merkle tree](https://proxy-prod.omnivore-image-cache.app/458x251,s93qXsqJY8Lar_nWZ7UGfGjrc_JLP-mZQHnckRn_tkEw/https://pangea.cloud/docs/assets/images/marvelous-merkle-trees-2-f02e7b2af03ebfec6f1c9a884a67d4f6.png)
			  
			  \#\# Merkle Tree Benefits[​](\#merkle-tree-benefits "Direct link to Merkle Tree Benefits")
			  
			  In order to understand why Merkle Trees are so prolific and why we, at Pangea, chose to use them for our [Secure Audit Log](https://pangea.cloud/services/audit-log/), it’s essential to understand their benefits.
			  
			  * _Small Storage Requirement_  
			  Due to Merkle Trees storing only hashes of the underlying data, the storage requirements are relatively small for the benefits they provide.
			  * _Fast, lightweight data validation_  
			  Compared to hash chaining or other data validation and consistency verification techniques, a Merkle proof is considerably smaller and faster to validate. Consider this, even as the number of leaf nodes in a Merkle Tree doubles, the number of hashes in a Merkle proof only grows by two.
			  * _Content Addressable_  
			  Content Addressability means that items are addressable by their content, rather than an artificial ID (e.g., sequence, GUID). A root hash in a Merkle Tree is unique based on the leaf nodes contained therein, thus making it content addressable. Moreover, each node in the tree is a hash of its contents as well. Content-addressable objects are inherently tamperproof, because to change the contents would be to change the address.
			  * _Consistency Verification_  
			  In a growing Merkle Tree, any previous root hash and thereby the data it represents can be proved to be included in a newly calculated root hash. Pangea’s Secure Audit Log refers to the proof required as a consistency proof, which is key to ensuring that records have not been inserted or deleted from the log.
			  
			  \#\# Merkle Trees in Action[​](\#merkle-trees-in-action "Direct link to Merkle Trees in Action")
			  
			  To further understand why the benefits of Merkle Trees matter, it’s helpful to know how and where they’re used in the real world.
			  
			  \#\# Crypto (BitCoin)[​](\#crypto-bitcoin "Direct link to Crypto (BitCoin)")
			  
			  Today, more people than ever are talking about Merkle Trees, largely due to its usage in cryptocurrency. The unique properties of Merkle Trees allow for fast transaction validation and minimize data replication required. [Here’s a great article](https://medium.com/blockchain-stories/the-tale-of-merkle-tree-in-bitcoin-blockchain-2c5fa5a298f7) on Merkle Trees and their usage in the Simplified Payment Verification (SPV) nodes of Bitcoin. For an interesting twist on what you know about Merkle trees, read about Ethereums usage of [Patricia Merkle Tries](https://ethereum.org/en/developers/docs/data-structures-and-encoding/patricia-merkle-trie/).
			  
			  \#\# Data Replication (Cassandra DB)[​](\#data-replication-cassandra-db "Direct link to Data Replication (Cassandra DB)")
			  
			  As mentioned several times, the root hash of a Merkle Tree is unique based on its contents. Some databases like Cassandra use Merkle Trees to validate replicas. By hashing each row a root and adding those hashes to a Merkle Tree, a unique root hash is generated for each data replica. Identifying inconsistencies between replicas is as trivial as comparing the two root hashes to see if they match. Further, when an inconsistency is found, one can compare each intermediate node to identify which rows have been corrupted. [This article](https://docs.datastax.com/en/archived/cassandra/3.0/cassandra/operations/opsRepairNodesManualRepair.html) is an excellent read for understanding in more detail how Cassandra uses Merkle trees for this process.
			  
			  \#\# Distributed File Systems (BitTorrent)[​](\#distributed-file-systems-bittorrent "Direct link to Distributed File Systems (BitTorrent)")
			  
			  Another example of a Merkle Tree implementation is in the BitTorrent Merkle Hash Extension. Typically torrent files contain a flat list of hashes representing each downloadable chunk of a content file. However, a problem arises when content files increase in size — either the size of the torrent file containing the list of hashes must increase, or the size of the chunks must increase. Neither of these are great options. The Merkle Hash Extension was created to solve this problem by allowing the root hash to be used for verification rather than a flat list of all hashes. [This article](http://bittorrent.org/beps/bep%5F0030.html\#:%7E:text=A%20Merkle%20hash%20can%20be,hash%20as%20data%20integrity%20protection) explains the usage in detail.
			  
			  \#\# Consistency Verification (Pangea Secure Audit Log)[​](\#consistency-verification-pangea-secure-audit-log "Direct link to Consistency Verification (Pangea Secure Audit Log)")
			  
			  I’d be remiss without pointing out that Pangea’s [Secure Audit Log](https://pangea.cloud/services/audit-log) uses Merkle Trees extensively for the validation of data and the consistency of that data. Using Merkle proofs, users can validate each log entry as untampered and a member of the Audit Log. Further, the integrity of the entire log can be validated using consistency proofs, guaranteeing that no records have been inserted or deleted from the logs.
			  
			  \#\# Wrapping Up[​](\#wrapping-up "Direct link to Wrapping Up")
			  
			  Merkle Trees are a fantastic contribution to Computer Science and have a great number of uses. At Pangea, we’re excited about our use of Merkle Trees in our [Secure Audit Log](https://pangea.cloud/services/audit-log/) service and would love to get your feedback on it. Sign up for our [Early Access Program](https://pangea.cloud/signup/) now.
			  
			  \#\# Get updates in your inbox and subscribe to our newsletter
	- [What is the difference between PBFT, Tendermint, HotStuff, and HotStuff-2?](https://omnivore.app/me/what-is-the-difference-between-pbft-tendermint-hot-stuff-and-hot-18c5726ee93)
	  collapsed:: true
	  site:: [decentralizedthoughts.github.io](https://decentralizedthoughts.github.io/2023-04-01-hotstuff-2/)
	  author:: Decentralized Thinkers
	  labels:: [[consensus-mechanisms]] [[merkle-airdrop]]
	  date-saved:: [[12/10/2023]]
	  date-published:: [[03/31/2023]]
		- ### Content
		  collapsed:: true
			- We recently published our work [HotStuff-2](https://eprint.iacr.org/2023/397.pdf) on eprint, introducing a two-phase HotStuff variant which simultaneously achieves O(n2) worst-case communication, optimistically linear communication, a two-phase commit regime within a view, and optimistic responsiveness in partially-synchronous BFT.
			  
			  The main takeaway is that two phases are enough for BFT after all.
			  
			  In this post, we will elaborate on the key observation made in the work, and compare and contrast it to relevant prior works: PBFT, Tendermint, and the original HotStuff. We will focus on explaining one key component that also forms the difference between these works – _how do we ensure liveness during a view change while simultaneously achieving other useful properties: responsiveness, good communication complexity, and fewer number of phases in the protocol?_
			  
			  HotStuff-2 is remarkably simple, adding no substantive complexity to the original HotStuff protocol. Hence, other aspects such as the way leaders change, differences in the normal case leader commit phase, pipelining, concurrency, and randomness are the same in HotStuff-2 as in HotStuff. Details regarding these aspects can be found in earlier posts, see the [suggested tutorials](\#suggested-tutorials) section at the bottom of the post for background material.
			  
			  \#\# Overview of Approaches
			  
			  For simplicity, we will assume that these partially synchronous protocols with n≥3t+1 are committing a single value, though the idea directly extends to multiple values. At the core, all of PBFT, Tendermint, HotStuff, and HotStuff-2 use (roughly) the same approach to obtain the safety property.
			  
			  In these protocols, in a _view_, parties hope to _certify_ and commit at most one value. Thus, they introduce one phase of votes between parties to ensure uniqueness of a value within the view. They then engage in another phase that allows parties to commit the value. A two-phase regime materializing this approach, where each phase uses a [linear secure broadcast](https://dl.acm.org/doi/10.1145/343477.343531), looks like the following. Note that party 4 is Byzantine in all of the examples below.
			  
			  ![](https://proxy-prod.omnivore-image-cache.app/0x0,sBFr1ja3Byv3DO3byW2iow3UulWtwY4smeTX4d6Dd3oQ/https://i.imgur.com/4yFLAhe.png)
			  
			  When a party commits a value v after the second phase, a principal invariant that is ensured is that ≥2t+1 parties (and thus ≥t+1 honest parties) are _locked_ on v from the first phase. These ≥t+1 honest parties would guard the safety of the commit. _Thus, they would not vote on a conflicting value unless they are shown a proof that it is safe to do so._
			  
			  Thus, all of these protocols rely on a lock-commit paradigm (also known as [commit-adopt](https://dl.acm.org/doi/10.1145/277697.277724)) where sufficiently many parties are locked before any party can commit. Consequently, if a leader fails or the network stalls, we can end up in one of three situations depicted below.
			  
			  ![](https://proxy-prod.omnivore-image-cache.app/0x0,s6G_5a5cW1cjTI3deqmc_7c4_xKSEkSGmln6HTn-jl5s/https://i.imgur.com/Yb4fiPc.png)
			  
			  1. No party has a lock and a fortioti, no value is committed.
			  2. One or a few parties are locked on a value, but no honest party has committed.
			  3. 2t+1 parties are locked, some honest parties have committed but not all.
			  
			  Observe that while case 1 is not great from the perspective of making progress, all parties are free to vote on other values in subsequent views. The key question is how do parties that are locked on a value, behave in the other two cases given that they do not know which scenario is the true system state. It turns out that all of these _safety-preferring_ protocols, the locked parties guard the safety of a _potential_ commit, i.e., by default assume we are in case 3, and not vote for a conflicting value unless shown a proof otherwise. When we are indeed in case 2, we need some mechanism to ensure that these locked honest parties vote for a safe proposal from a leader (perhaps conflicting with a locked value) after a view-change. The different schemes differ in this regard. Note that since all of these are safety-preferring protocols, we are only concerned about an honest leader making progress — a malicious leader, at the most, can delay progress, and it can do so by simply not sending a proposal in the view.
			  
			  \#\# How does the view-change protocol differ between PBFT, Tendermint, HotStuff, and HotStuff-2?
			  
			  While reading about these protocols, it may be beneficial to think about these two questions: _(i) What does the leader learn about the status of the system (w.r.t. the three scenarios) at the start of a view? (ii) How does the leader convince other parties about the status of the system (and thus to vote for its proposal)?_
			  
			  \#\#\# PBFT
			  
			  In PBFT, the leader collects a status of locks from 2t+1 parties at the start of a view. Consider case 3 depicted above, namely, that some party has committed in earlier views. Among the 2t+1 locks in the status, up to t can be malicious, up to t can be from honest parties are not locked on the committed value, but there is at least one honest party locked on the committed value. That party would not vote for a leader proposal conflicting with the lock it holds, thus guarding the safety of the commit. Moreover, the leader would necessarily learn about that lock when it collects the status message.
			  
			  Now consider case 2 depicted below, namely, no party had committed in an earlier view, but some parties (in the figure below, parties 1 and 4) locked on the value. Their status may or may not be a part of the locks the leader receives. For instance, we can be in a scenario where the leader receives a status from all parties except party 1, and Byzantine party 4 does not report its lock. In this case, the leader is actually guaranteed that no honest party may have committed the value and is free to propose any value.
			  
			  ![](https://proxy-prod.omnivore-image-cache.app/0x0,sIU1uAUXmC7RQrPKBMCJJae3UXpkEz0ysLOyoozH-Z-0/https://i.imgur.com/PxGS3bj.png)
			  
			  How does the leader convince the honest parties locked on a conflicting value to vote for the value it proposed? It sends the _status certificate_ containing the 2t+1 locks in its proposal. For example, in the figure below, the leader provides (absence of) locks from itself, party 3, and party 4 (who is lying). Observe that every honest party can apply the same reasoning as the leader did, and thus know that it is safe to vote for the value. In particular, this holds even in situations when a party is locked on a value and the leader proposes a different value that is justified by the status certificate. In the figure above, party 1 is locked in a previous proposal but it will vote for the leader proposal. In other words, the status certificate from an honest leader provides sufficient information to all honest parties to vote on the proposal.
			  
			  Note that sending this message can be responsive since the leader can act as soon as it receives 2t+1 locks. However, the status certificate has linear complexity and thus sending it in the proposal leads to a quadratic communication complexity.
			  
			  \#\#\# Tendermint
			  
			  Tendermint improves PBFT by not requiring the leader to send a (2t+1)\-sized status certificate and thus can perform a view change with linear complexity. Well, how can a leader convince honest parties would indeed vote for it? Observe that by receiving 2t+1 locks, an honest leader perhaps knows what to propose, but if parties do not have access to those locks (through a status certificate), they may not vote for it. In particular, in a situation where some honest party p is locked on a value, and a leader proposes a conflicting value, p cannot distinguish whether we are in case 2 or case 3 in the scenarios described above. A generalization of this dilemma for this party is presented as a livelessness attack in [HotStuff](https://arxiv.org/pdf/1803.05069.pdf).
			  
			  ![](https://proxy-prod.omnivore-image-cache.app/0x0,s3pLpORuOigE-2dSnHXvkMSjP6Xmr6dNm_dbgRdBfwck/https://i.imgur.com/zMYcMB6.png)
			  
			  To address this concern, Tendermint requires the leader to wait for an O(Δ) time at the start of the view. After GST, the O(Δ) wait ensures that the leader receives locks from _all_ honest parties. In the figure above, the leader will obtain the highest lock value from party 1\. Thus, it can send a proposal that conforms with the value corresponding to the lock from the highest view, and send this lock together with the proposal. The highest-ranked lock convinces _all_ honest parties to vote on the proposal sent by the leader. Note that, in this solution, while the leader learns the globally highest-ranked lock, the parties do not. However, the amount of information is sufficient to ascertain that the proposal is safe to vote on.
			  
			  Tendermint obtains a linear communication complexity for view change compared to PBFT’s quadratic communication complexity. However, due to the O(Δ) wait, the protocol is not responsive.
			  
			  \#\#\# HotStuff
			  
			  The HotStuff protocol simultaneously obtains a linear view change and responsiveness when the leader is honest after GST. HotStuff addresses the livelessness concern differently while still ensuring that the value corresponding to the highest lock is proposed by the leader. Abstractly speaking, it uses the same argument as the one used for safety. For safety, we said, “if some party commits, then ≥2t+1 parties hold a lock that will guard the safety of the commit, and ensure that the next leader receives it”. For liveness, HotStuff introduces another phase of votes and obtains a similar invariant: “if some party locks, then ≥2t+1 parties know about the existence of this lock and thus hold a _key_ corresponding to it. This key will be shared with the next leader to decide on a proposal appropriately.”![](https://proxy-prod.omnivore-image-cache.app/0x0,sbyt4DJCRgax2Q_WTj1gzqE8MEWbKhGcAQ87NXv79cD8/https://i.imgur.com/fitJEFX.png)
			  
			  In the figure below, a leader failure or poor network at a critical moment leaves parties 1 and 4 locked; the extra phase guarantees that 2t+1, namely parties 1, 3, and 4, already obtained a key corresponding to this lock. Note that, in particular, party 3 has a key despite not reaching the lock step.
			  
			  ![](https://proxy-prod.omnivore-image-cache.app/0x0,saGJweg4URGFKsIf3cs-mApKO2xIdrxLER-yJHX4qepQ/https://i.imgur.com/1C6i7jT.png)
			  
			  Correspondingly, the next leader would learn about the highest lock through the 2t+1 keys it receives, and the proposal would respect the globally highest lock held by any honest party. In the example, the new leader (party 2) obtains the key from party 3 (Byzantine party 4 may not send its key). Note that, while locks guard the safety of a commit, keys do not, and thus honest parties only holding a higher key on a different value than the proposal can still vote for the proposal.
			  
			  Thus, HotStuff obtains linear view change and responsiveness, but introducing the _key phase_ makes it a three-phase protocol.
			  
			  \#\#\# HotStuff-2
			  
			  Our work takes a fresh look at the livelessness concern and asks, _do we really need to add another phase to address this concern while still obtaining linear communication complexity and optimistic responsiveness?_ Following the above discussion, if a leader knows about the highest lock _and_ it can convince all honest parties about it, then the problem is solved.
			  
			  The key observation is that a new leader can choose between two options:
			  
			  * If the leader obtains a lock (a quorum certificate) from the preceding view, it **knows** that it has obtained the maximal locked value that possibly exists in the system. In this case, it proceeds with a proposal in a responsive manner.
			  * Otherwise, the leader **knows** that a timer delay of Ω(Δ) must have expired in the preceding view. In that case, there is no responsiveness anyway, hence it waits an extra O(Δ) delay after all parties are guaranteed to enter the view to obtain the maximal locked value in the system.
			  
			  Indeed if a leader would receive a lock corresponding to the previous view, there _cannot_ exist an even higher lock. Thus, a proposal respecting this lock would be voted for by all honest parties and the livelessness concern does not exist. If the leader does not obtain such a lock from the previous view, it would wait to hear about the locks from all honest parties by waiting O(Δ) time — this can happen when the leader from the previous view is malicious or the previous view was before GST. However, in those cases, we cannot hope to obtain responsiveness anyway. Thus, if we have a sequence of honest leaders after GST, each of them is guaranteed to drive progress responsively and generate a certificate in a view that will aid the next leader. Thus, all leaders except the first one in the chain can make honest parties commit responsively.
			  
			  Revisiting the example above, in HotStuff-2 one of the following two scenarios depicted below may happens:
			  
			  * Scenario 1: Some parties may not commit in a view but they become locked in it; the highest lock is obtained by the next view leader and it proceeds responsively.
			  * Scenario 2: No (honest) party obtains a lock on a value in a view, and the next view leader has to wait Δ to propose in the next view.
			  
			  ![](https://proxy-prod.omnivore-image-cache.app/0x0,sj22qbF0DKyfHsFlzKrg8-zPLMOrz5H2MJ5sXEwwL__Q/https://i.imgur.com/dDVmH8r.png)
			  
			  It’s worth noting that using a dual leader regime differentiating between the case of a normal/faulty preceding view has been used in prior works; see the [HotStuff-2 manuscript](https://eprint.iacr.org/2023/397.pdf) for a detailed discussion of related works. The first one (to our knowledge) is [Pala](https://eprint.iacr.org/2018/981.pdf) which introduced a dual regime into the Tendermint protocol. Subsequently, several works have attempted to improve the number of phases in the HotStuff protocol using a dual leader regime. This includes [Fast-HotStuff](https://arxiv.org/abs/2010.11454) and a recent [post](https://decentralizedthoughts.github.io/2022-11-24-two-round-HS/) that adds a Δ wait to Tendermint and to the [original two-phase HotStuff paper](https://arxiv.org/pdf/1803.05069v1.pdf), but with no discussion of responsiveness or view synchronization.
			  
			  The protocol modification in HotStuff-2 is remarkably simple, adding no substantive complexity to the original HotStuff protocol. The essence of our result is not in a new protocol but understanding that a simple solution such as this suffices and we can simultaneously obtain a linear communication complexity view change with optimistic responsiveness, worst-case quadratic complexity while still committing within two phases. Our key observation is subtle, but once the insight is understood, really simple (at least we think so!), allowing us to solve the problem without any heavy machinery.
			  
			  \#\# Summary
			  
			  Here’s a summary of the differences between these protocols.
			  
			  | |  Phases  | Worst-case complexity | View-change communication | Responsive view-change? |     |
			  | ---------- | --------------------- | ------------------------- | ----------------------- | --- |
			  | PBFT       | 2                     | O(n3)                     | O(n2)                   | Yes |
			  | Tendermint | 2                     | O(n2)                     | O(n)                    | No  |
			  | HotStuff   | 3                     | O(n2)                     | O(n)                    | Yes |
			  | HotStuff-2 | 2                     | O(n2)                     | O(n)                    | Yes |
			  
			  \#\# Suggested Tutorials
			  
			  * [Provable Broadcast (2022)](https://decentralizedthoughts.github.io/2022-09-10-provable-broadcast/)
			  * [On PBFT from Locked Broadcast (2022)](https://decentralizedthoughts.github.io/2022-11-20-pbft-via-locked-braodcast/)
			  * [Two-Round HotStuff (2022)](https://decentralizedthoughts.github.io/2022-11-24-two-round-HS/)
			  * [What is the difference between PBFT, Tendermint, SBFT and HotStuff? (2019)](https://decentralizedthoughts.github.io/2019-06-23-what-is-the-difference-between/)
			  * [HotStuff: Three-Chain Rules! (2019)](https://malkhi.com/posts/2019/08/hotstuff-three-chain-rules/)
			  * [The BFT Lens: Tendermint (2018)](https://malkhi.com/posts/2018/04/BFT-lens-tndrmnt/)
			  * [The BFT Lens: HotStuff and Casper (2018)](https://malkhi.com/posts/2018/03/bft-lens-casper/)
			  
			  Please add your comments on [Twitter](https://twitter.com/kartik1507/status/1642214584277663746?s=20).
			  
			  **Acknowledgment.** We thank Benjamin Chan for providing feedback on this post.
	- [What is a Merkle Tree?](https://omnivore.app/me/what-is-a-merkle-tree-18c57202f64)
	  collapsed:: true
	  site:: [decentralizedthoughts.github.io](https://decentralizedthoughts.github.io/2020-12-22-what-is-a-merkle-tree/)
	  author:: Decentralized Thinkers
	  labels:: [[cryptography]] [[merkle-airdrop]]
	  date-saved:: [[12/10/2023]]
	  date-published:: [[12/21/2020]]
		- ### Content
		  collapsed:: true
			- In this post, we will demystify _Merkle trees_ using three examples of problems they solve:
			  
			  1. Maintaining integrity of files stored on Dropbox.com, or _file outsourcing_,
			  2. Proving a transaction between Alice and Bob occurred, or _set membership_,
			  3. Transmitting files over unreliable channels, or _anti-entropy_.
			  
			  (1)
			  
			  By the end of the post, you’ll be able to understand **key concepts** that, at this point, might intimidate you:
			  
			  1. A Merkle tree is[1](\#fn:consideredtobe) a **collision-resistant hash function**, denoted by MHT, that takes n inputs (x1,…,xn) and outputs a _Merkle root hash_ h\=MHT(x1,…,xn),
			  2. A verifier who only has the root hash h can be given an xi and an associated **Merkle proof** which convinces them that xi was the ith input used to compute h.  
			   * In other words, convinces them that there exist other xj’s such that h\=MHT(x1,…,xi−1,xi,xi+1,…,xn).  
			   * This ability to verify that an xi is the element at the ith position against the root hash h (i.e., without having to store all n inputs) is the fundamental power of Merkle trees which we explore in this post.
			  3. If a Merkle proof says that xi was the ith input used to computed h, no attacker can come up with another Merkle proof that says a different xi′≠xi was the ith input.  
			   * More formally, an attacker cannot come up with a Merkle root h and two values xi≠xi′ with proofs πi and πi′ that both verify for position i w.r.t. h.
			  
			  \#\# Prerequisites
			  
			  Merkle trees are built using an **underlying** _cryptographic hash functions_, which we assume you understand. If not, just read [our post on hash functions](https://decentralizedthoughts.github.io/2020-08-28-what-is-a-cryptographic-hash-function)!
			  
			  **Definition:** A hash function H is collision resistant if it is computationally-intractable[2](\#fn:handwave) for an adversary to find two different inputs x and x′ with the same hash (i.e., with H(x)\=H(x′)).
			  
			  **Notation:**
			  
			  * We often use \[k\]\={1,2,…,k} and \[i,j\]\={i,i+1,…,j−1,j}.
			  * Although a hash function H(x) is formalized as taking a single input x, we often invoke it with two inputs as H(x,y). Just think of this as H(z), where z\=(x | y) and | is a special delimiter character.
			  
			  Suppose you have n\=8 files, denoted by (f1,f2,…,f8), you have a [collision-resistant hash function](https://decentralizedthoughts.github.io/2020-08-28-what-is-a-cryptographic-hash-function) H and you want to have some fun.
			  
			  You start by hashing each file as hi\=H(fi):
			  
			  You could have a bit more fun by continuing to hash every two adjacent hashes:
			  
			  You could even go crazy and continue on these newly obtained hashes:
			  
			  In the end, you only live once, so you’d better hash these last two hashes as h1,8\=H(h1,4,h4,8):
			  
			  **Congratulations!**What you have done is computed a Merkle tree on n\=8 **leaves**, as depicted in the picture above.
			  
			  Note that every **node** in the tree stores a hash:
			  
			  * The ith **leaf** of the tree stores the hash hi of the file fi.
			  * Each **internal node** of the tree stores the hash of its two children.
			  * The h1,8 hash stored in the **root node** is called the **Merkle root hash**.
			  
			  You could easily generalize and compute a Merkle tree over any number n of files.
			  
			  It is useful to _think of computing the Merkle tree as computing a collision-resistant hash function_, denoted by MHT, which takes n inputs (e.g., the n files) and outputs the Merkle root hash. For example, we will often use the following notation:
			  
			  (2)h1,8\=MHT(f1,f2,…,f8)
			  
			  Importantly, note that computing MHT (i.e., computing the Merkle tree), involves many computations of its **underlying collision-resistant hash function** H.
			  
			  At the risk of overwhelming you with notation, it is useful to observe that h1,8 has a “recursive” structure:
			  
			  h1,8\=MHT(f1,…,f8)\=H(H(H(H(f1),H(f2)),H(H(f3),H(f4)),),H(H(H(f5),H(f6)),H(H(f7),H(f8)),))
			  
			  Really this is just a (verbose) mathematical representation of the Merkle tree that we visually depicted above!
			  
			  We often refer to a file fi as **“being in the Merkle tree”** to indicate it was one of the n input files used to compute the tree.
			  
			  \#\# This is a Merkle proof!
			  
			  Alright, you’ve computed your Merkle tree over your 8 files.
			  
			  Next, you upload your files **and** Merkle tree on Dropbox.com and delete everything from your computer except the Merkle root h1,8. Your goal is to later download any one of your files from Dropbox **and** make sure Dropbox did not accidentally corrupt it.
			  
			  This is the **file integrity** problem and Merkle trees will help you solve it.
			  
			  The **key idea** is that, after you download fi, you ask for a small part of the Merkle tree called a **Merkle proof**. This proof enables you to verify that the downloaded fi was not accidentally or maliciously modified.
			  
			  But how do you verify?
			  
			  Well, observe that the Merkle proof for fi is exactly the subset of hashes in the Merkle tree that, together with fi, allow you to recompute the root hash of the Merkle tree and check it matches the real hash h1,8, **without knowing any of the other hashed files**.
			  
			  So, to verify the proof, you simply “fill in the blanks” in the picture above by computing the missing hashes depicted with dotted boxes, in this order:
			  
			  h3′\=H(f3)h3,4′\=H(h3′,h4)h1,4′\=H(h1,2,h3,4′)h1,8′\=H(h1,4′,h5,8)
			  
			  Lastly, you check that the Merkle root h1,8′ you computed above is equal to the Merkle root h1,8 you kept locally! If that’s the case, then you can be sure you downloaded the correct fi (and we prove this later).
			  
			  But why does this check suffice as a proof that fi was downloaded correctly? Here’s some intuition. Since the Merkle proof verified, this means you were able to recompute the root hash h1,8 by using fi as the ith input and the Merkle proof as the remaining inputs. If the proof verification had yielded the same hash h1,8 but with a different file fi′≠fi as the ith input, then this would yield a collision in the underlying hash function H used to build the tree. This last observation is not trivial to see but we will help you see it later, when we argue security formally. 
			  
			  \#\#\# Why use large Merkle proofs anyway?
			  
			  Forget the Merkle tree! Since you only have eight files, you could check integrity by storing their hashes hi\=H(fi) rather than their Merkle root h1,8\=MHT(f1,…,f8). After all, the hi hashes are much smaller than the files themselves.
			  
			  Then, when you download fi, you hash it as yi\=H(fi) and check that hi\=yi. Since H is [collision-resistant](https://decentralizedthoughts.github.io/2020-08-28-what-is-a-cryptographic-hash-function), you can be certain that fi was not modified. (Indeed, we already discussed how [hash functions can be used for download file integrity](https://decentralizedthoughts.github.io/2020-08-28-what-is-a-cryptographic-hash-function) in our previous post.)
			  
			  One advantage of this approach is you no longer need to download Merkle proofs.
			  
			  Unfortunately, the problem with this approach is you have to store n hashes when you outsource n files. While this is fine when n\=8, it is no so great when n\=1,000,000,000!
			  
			  _“But that’s crazy! Who has one billion files?”_ you might protest.
			  
			  Well, just take a look at the [Certificate Transparency (CT)](https://en.wikipedia.org/wiki/Certificate%5FTransparency) project, which builds a Merkle tree over the set of all digital certificates of HTTPS websites. These Merkle trees easily have hundreds of millions of leaves and are designed to scale to billions.
			  
			  **Moral of the story:**To avoid the need for the verifier to store a hash for each one of the n outsourced file, we use Merkle trees. This way, you only need to store a Merkle root hash (rather than n hashes) and receive an O(log⁡n)\-sized Merkle proof with each downloaded file.
			  
			  If you are still concerned about large Merkle proof size, you should look at more _algebraic_ **vector commitments (VCs)**, such as recent ones based on [polynomial commitments](https://alinush.github.io/2020/05/06/aggregatable-subvector-commitments-for-stateless-cryptocurrencies.html) or on [RSA assumptions](https://alinush.github.io/2020/11/24/Catalano-Fiore-Vector-Commitments.html). However, be aware that VCs come with their own performance bottlenecks and other caveats.
			  
			  \#\# What else is a Merkle tree useful for?
			  
			  Now that we know how a Merkle tree is computed and how Merkle proofs work, let’s dig into a few more use-cases.
			  
			  \#\#\# Efficiently proving Bitcoin transactions were validated
			  
			  Recall that a Bitcoin block is just a _set of transactions_ that were validated by a miner.
			  
			  **Problem:**Sometimes it is useful for _Alice_, who is running Bitcoin on her mobile phone, to verify that she received a payment transaction from _Bob_.
			  
			  ![](https://proxy-prod.omnivore-image-cache.app/0x0,sUV1XU8FfrH4xk86Y5htdvP9vdGzFR7USLp-RQgpUwN0/https://decentralizedthoughts.github.io/uploads/merkle-bitcoin-1.png)
			  
			  **Inefficient, consensus-based solution:**Alice could simply download every newly mined Bitcoin block on her phone and inspect the block for a transaction from Bob that pays her. But this requires Alice to download a lot of data (1 MiB / block), which can be either slow or expensive, since mobile data costs money._(The unstated assumption here is that Alice relies on Bitcoin’s proof-of-work consensus protocol to decide whether a block is valid. These consensus-related details are covered in other posts[3](\#fn:post1),[4](\#fn:post2) on this blog.)_
			  
			  **Insecure, polling-based solution:**Note that Alice cannot just simply ask nodes on the Bitcoin network, _“Hey, was I paid by Bob?”_ since nodes can lie and say _“Yes, you were”_ showing her a transaction from Bob that is actually not yet incorporated into a block.
			  
			  **Efficient, Merkle-based solution:**If Alice was indeed paid by Bob, then Bitcoin can prove this to her via a **Merkle proof**. Specifically, Alice will ask a Bitcoin node if she was paid by Bob in the latest block, but instead of simply trusting the _“Yes, you were paid and here’s the transaction”_ answer, she will ask the node to _prove membership of the transaction_ in the block via a Merkle proof.
			  
			  Importantly, Alice never has to download the full block: she only needs to download a small part of the block called the **block header**, which contains the root of a Merkle tree built over all transactions in that block[5](\#fn:catena). This way, Alice can verify the Merkle proof leading to Bob’s transaction in this tree, which will assure her that Bob’s transaction is in the block without having to download the other transactions.
			  
			  ![](https://proxy-prod.omnivore-image-cache.app/0x0,sHfD6cW1O86pJFR4-xSzYoA-HtIB70_ofRJo2OXLtHEc/https://decentralizedthoughts.github.io/uploads/merkle-bitcoin-2.png)
			  
			  This Merkle-based solution still requires Alice to rely on Bitcoin’s proof-of-work consensus to validate block _headers_. However, since headers are 80 bytes, this is much more efficient than downloading full (1 MiB) blocks. Furthermore, some of you might note that, because of Bitcoin’s _chronologically-ordered_ Merkle tree, a node can still lie and say _“No, you weren’t paid by Bob”_ and Alice would have no way to tell the truth _efficiently_ without actually downloading every new block and inspecting it. One way this problem could be solved is by re-ordering Bitcoin’s Merkle tree, either by the payer or by the payee’s Bitcoin address. We leave the details of this to another post.
			  
			  **Moral of the story:**The beauty of Merkle trees is that a _prover_, who has a large set of data (e.g., thousands of transactions) can convince a _verifier_, who has access to the set’s Merkle root hash, that a piece of data (e.g., a single transaction) is in this large set by giving the verifier a Merkle proof.
			  
			  \#\#\# Downloading files over corrupted channels, or anti-entropy via Merkle trees
			  
			  In our previous example, we showed how you could outsource your files to Dropbox and **detect** malicious or accidental modifications of any of your files.
			  
			  Suppose the modifications were accidental due to an unreliable connection to Dropbox. It would be nice if you could not just _detect_ these modifications but actually **recover** from them and eventually download the original, unmodified file.
			  
			  **The naive solution** would be to simply restart the file download whenever you detect a modification via the Merkle-based technique we discussed before. However, this could be painfully slow. In fact, if the connection is sufficiently unreliable and if the file is sufficiently large, this might never terminate.
			  
			  A **better solution** is to split the file into **blocks** and use the Merkle tree to detect modifications _at the block level_ (i.e., at a finer granularity) rather than at the file level. This way, you only need to restart the download for incorrectly downloaded blocks, which helps you make steady progress.
			  
			  To keep things simple, we will focus on a simpler scenario where just one file is outsourced to Dropbox rather than n files. We will discuss later how this can be generalized to n files.
			  
			  \#\#\#\# Inefficient: Recovering corrupted file blocks with one Merkle proof per block
			  
			  As we said above, we will split the file f into, say, b\=8 **blocks**:
			  
			  (3)f\=(f1,f2,…,f8)
			  
			  Then, we will build a Merkle tree over these 8 blocks:
			  
			  ![](https://proxy-prod.omnivore-image-cache.app/0x0,sSg2VQFDipT7rrx6S8fUr4X3LBDKeSb6S3ZPl5W9Bpqg/https://decentralizedthoughts.github.io/uploads/merkle-anti-entropy-1.png)
			  
			  As before, you send f and the Merkle tree to Dropbox, and you store h1,8 locally.
			  
			  Next, to download f reliably, you will now download each block of f with its Merkle proof, which you verify as discussed in the beginning of the post. And if a block’s proof does not verify, you ask for that block and its proof again until it does. Ultimately, the unreliable channel will become reliable and the proof will verify.
			  
			  This approach is better than the previous one because, when the channel is unreliable, you do not need to restart the download of f from scratch. Instead, you only restart the download for the specific block of f that failed downloading.
			  
			  Note that there’s an interesting choice of block size to be made, as a function of the unreliability of the channel. However, this is beyond the purpose of this post. Also note that there are other ways to deal with unreliable channels, such as error-correcting codes, which again are beyond the purpose of this post.
			  
			  Unfortunately, in this **first solution**, you are re-downloading the full Merkle tree, in addition to the blocks themselves. This is because Dropbox sends a Merkle proof for _every_ block[6](\#fn:dedup), **even if that block is correct**.
			  
			  We will fix this next.
			  
			  \#\#\#\# Recovering corrupted file blocks with one Merkle proof per _corrupted_ block
			  
			  A **better solution** is to observe that you can first _optimistically_ download all b\=8 blocks, and rebuild the Merkle tree over them. If you get the same root hash h1,8, you have downloaded the file f correctly and you are done!
			  
			  Otherwise, let’s go through an example to see how you would identify the corrupted blocks. Assume, for simplicity, that only block 5 (denoted by f5) is corrupted. Then, the Merkle tree you re-compute during the download would differ _only slightly_ from the one you originally computed above.
			  
			  Specifically, you would re-compute the tree below, with the difference highlighted in red:
			  
			  ![](https://proxy-prod.omnivore-image-cache.app/0x0,sczRugRyAofNXa7BZhN3Ck68TBVQYQUwSu2qILK8axIs/https://decentralizedthoughts.github.io/uploads/merkle-anti-entropy-2.png)
			  
			  If all blocks were correct, you expect the root hash of the Merkle tree above to be h1,8. However, the blocks you downloaded yielded a different root hash h1,8′. This tells you some of the blocks are corrupted!
			  
			  Even better, you realize that either:
			  
			  1. Some of the first b/2 blocks were corrupted,
			  2. Some of the last b/2 blocks were corrupted,
			  3. Or both!
			  
			  And because you have the actual root hash h1,8, you can actually tell which one of these cases you are in! How? You simply ask for the children (h1,4,h5,8) of the root h1,8 until you receive the correct ones that verify: i.e., the ones such that h1,8\=H(h1,4,h5,8).
			  
			  Once you have the correct children, you immediately notice that you computed the correct h1,4 but computed a different h5,8′ instead of h5,8. This tells you the first 4 blocks were correct, but the last 4 were not. As a result, you can now ignore the first (correct) half of the Merkle tree for blocks f1,…,f4 and focus on the second (corrupted) half for blocks f5,…,f8.
			  
			  ![](https://proxy-prod.omnivore-image-cache.app/0x0,ssIxKdfscjG0LPF3PfofCJHnCo19LkfFPL-Gvuxd-b3A/https://decentralizedthoughts.github.io/uploads/merkle-anti-entropy-3.png)
			  
			  In other words, you have now reduced your initial problem of to a smaller subproblem! Specifically, you must now identify the corrupted block amongst blocks f5,…,f8. And, since you now know that their real Merkle root hash is h5,8, you just need to recursively apply the same technique!
			  
			  Importantly, you should convince yourself that this approach works even if there is more than one corrupted block: you will just have more sub-problems. Furthermore, note that if all blocks are corrupted, then this approach effectively downloads all Merkle hashes in the tree. However, if just one block is corrupted, this approach will only download the hashes along the path to that block (i.e., the ones in red in the figure above) and the Merkle proof for that block (i.e., the sibling nodes of the red nodes).
			  
			  In general, this approach only downloads (roughly) a Merkle proof _per corrupted block_, without re-downloading common hashes across different proofs. In contrast, the first solution downloaded one Merkle proof _per downloaded block_, even if the block was correct!
			  
			  \#\#\#\# Generalizing to more than one file
			  
			  We can generalize the approach above to multiple files. The key idea is to build a Merkle tree over each file’s blocks as already described. If we have n files, we get n Merkle trees with root hashes r1,r2,…,rn−1 and rn, respectively. Next, we build another Merkle tree over these root hashes. Lastly, denote this tree’s root hash by z1,n.
			  
			  For example, here’s what this would look like when n\=8:
			  
			  ![](https://proxy-prod.omnivore-image-cache.app/0x0,swmooD9jfOkXeuzY58biFCA8_G99-7fxLwkHjNWZFmHk/https://decentralizedthoughts.github.io/uploads/merkle-anti-entropy-4.png)
			  
			  Now, when downloading, say, the 2nd file f2 over an unreliable channel, you first ask for the 2nd leaf of the Merkle tree with root z1,8, which is r2, together with a Merkle proof. Once again, because the channel is unreliable, you might have to ask multiple times until the proof verifies. Finally, once you have r2, you can run the protocol described above, since you have the root hash of f2’s Merkle tree!
			  
			  \#\# Want more?
			  
			  Well, I hope you found all of this fascinating and want to learn more. You could start by going to the bonus section below and reading our formal security proof for Merkle trees.
			  
			  Then, you could read my three favorite Merkle tree papers, which I think are highly approachable even for beginners.
			  
			  First, you should read the paper on **history trees** by Crosby and Wallach[7](\#fn:CW09). History trees are Merkle trees that “grow” from left to right, in the sense that one is only allowed to append new leafs to the right of the tree.
			  
			  Despite their simplicity, history trees are incredibly powerful since they support _append-only proofs_: given an older tree of t leaves and a new tree of t′\=t+Δ leaves, one can prove (using a succinct O(log⁡t′)\-sized proof) that the new tree includes all the leaves from the old tree. This makes history trees very useful for building append-only logs such as [Certificate Transparency (CT)](https://en.wikipedia.org/wiki/Certificate%5FTransparency), which is at the core of securing HTTPS.
			  
			  _“Append-only logs? Don’t you mean blockchains?”_ you ask. Nope, I do not. These logs have a different mechanism to detect (rather than prevent) forks. However, each fork is always provably extended in append-only fashion using the proofs described above.
			  
			  Second, you should read the paper on CONIKS by Melara et al[8](\#fn:MBBplus15). CONIKS is also a transparency log, but geared more towards securing instant messaging apps such as Signal, rather than HTTPS. One interesting thing you’ll learn from this paper is how to lexicographically-order your Merkle trees so you can prove something is **not** in the tree, as we briefly touched upon in the Bitcoin section. In fact, I believe this paper takes the most sane, straightforward approach to doing so. Specifically, CONIKS builds a **Merkle prefix tree**, which is much simpler to implement than any binary search tree or treap (at least in my own experience). It also has the advantage of having expected O(log⁡n) height if the data being Merkle-ized is not adversarially-produced.
			  
			  A related paper is would be the Revocation Transparency (RT) manuscript[9](\#fn:LK15), which CONIKS can be regarded as improving upon in terms of proof size and other dimensions.
			  
			  Third, you should read the Verifiable Data Structures[10](\#fn:ELC16) manuscript by the Certificate Transparency (CT) team, which combines a history tree with a lexicographically-ordered tree (such as CONIKS) into a single system with its own advantages.
			  
			  At the end of the day, I think what I’m trying to say is _“why don’t you go read about transparency logs and come write a blog post on Decentralized Thoughts so I don’t have to do it!”_ :)
			  
			  \#\# Bonus: A Merkle tree is a collision-resistant hash function
			  
			  A very simple way to think of a Merkle hash tree with n _leaves_ is as a collision-resistant hash function MHT that takes n inputs[11](\#fn:contrast) and ouputs a 2λ\-bit hash, a.k.a. the _Merkle root hash_. More formally, the _Merkle hash function_ is defined as:
			  
			  (4)MHT:({0,1}∗)n→{0,1}2λ
			  
			  And the Merkle root of some input x→\=(x1,…,xn) is denoted by:
			  
			  (5)h\=MHT(x1,…,xn)
			  
			  Here, λ is a _security parameter_ typically set to 128, which implies Merkle root hashes are 256 bits.
			  
			  **Theorem (Merkle trees are collision-resistant)**: It is unfeasible to find two sets of leaves x→\=(x1,…,xn) and x→′\=(x1′,…,xn′) such that x→≠x→′ but MHT(x→)\=MHT(x′→).
			  
			  Instead of proving this theorem, we’ll prove an even stronger one below, which implies this one. However, if you want to prove this theorem, all you have to do is show that the existence of these two “inconsistent” sets of leaves implies a collision in the underlying hash function H. In fact, in the proof, you will “search” for this collision much like the anti-entropy protocol described above searches for corrupted blocks!
			  
			  **Theorem (Merkle proof consistency):** It is unfeasible to output a Merkle root h and two “inconsistent” proofs πi and πi′ for two different inputs xi and xi′ at the ith leaf in the tree of size n.
			  
			  **Proof:**The Merkle proof for xi is πi\=((h1,b1),…,(hk,bk)), where the hi’s are **sibling hashes** and the bi’s are **direction bits**. Specifically, if bi\=0, then hi is a left child of its parent node in the tree and if bi\=1, then it’s a right child.
			  
			  In our previous discussion, we never had to bring up these _direction bits_ because we always visually depicted a specific Merkle proof. However, here, we need to reason about _any_ Merkle proof for _any_ arbitrary leaf. Since such a proof can “take arbitrary left and right turns” as it’s going down the tree, we use these direction bits as “guidance” for the verifier. (A careful reader might notice that the direction bits can actually be derived from the leaf index i being proved and don’t actually need to be sent with the proof: the direction bits are obtained by flipping i’s binary representation.)
			  
			  Roughly speaking, to verify πi, the verifier uses xi together with the sibling hashes and the direction bits to compute the hashes (z1,…,zk+1) along the path from xi to the root. More precisely, the verifier:
			  
			  1. Sets z1\=xi.
			  2. For each j∈\[2,k\], computes zj as follows:  
			   * If bj−1\=1, then zj\=H(zj−1,hj−1)  
			   * If bj−1\=0, then zj\=H(hj−1,zj−1)
			  
			  Lastly, the verifier checks if zk+1 equals the Merkle root hash h. If it does, then the verification succeeds. Otherwise, it fails.
			  
			  Do not be intimidated by all the math above: we are merely generalizing the Merkle proof verification that we visually depicted in the Dropbox file outsourcing example at the beginning of this post.
			  
			  Similarly, the proof for xi′ is πi′\=((h1′,b1),…,(hk′,bk)). Note that the hi′ hashes could differ from the hi hashes, but the direction bits are the same, since both proofs are for the ith leaf in the tree.
			  
			  Since both proofs verify, the verification of the second proof πi′ for xi′ will yield hashes {z1′,z2′,…,zk+1′} along the same path from xi′ to the root such that zk+1′\=h.
			  
			  But recall from the verification of the first proof πi that we also have zk+1\=h. Thus, zk+1\=zk+1′. This is merely saying that, since both proofs verify, they yield the same root hash h\=zk+1\=zk+1′.
			  
			  The next step is to reason about how the two different xi≠xi′ could have possibly “hashed up” to the same root hash h. (Spoiler alert: only by having a collision in the underlying hash function H.) I think this is best explained by considering a few extreme cases and then generalizing. (Note that these are not the _only_ two cases; just two particularly enlightening ones.)
			  
			  **Extreme case \#1**: One way would have been for the proof verification to yield zj≠zj′ for all j∈\[k\] (but not for j\=k+1 since that’s the level of the Merkle root). In this case, without loss of generality, assume bk\=1. Then, we would have h\=zk+1\=H(zk,hk) and h\=zk+1′\=H(zk′,hk′). But since zk≠zk′, this gives a collision in H! (Alternatively, if bk\=0, just switch the inputs to the hash function.)
			  
			  **Extreme case \#2**: Another way would have been for the proof verification to yield zj\=zj′ for all j∈\[2,k+1\] (but not for j\=1 since that’s the level of xi and xi′ and they are not equal). In this case, without loss of generality, assume b1\=1. Then, we would have z2\=H(x1,h1) and z2′\=H(x1′,h1′). (Again, if bk\=0, just switch H’s inputs.) But since z2\=z2′ and xi≠xi′, this gives a collision in H!
			  
			  The point here is to see that, no matter what the two inconsistent proofs are, one can always work their way back to a collision in H, whether that collision is at the top of the tree (extreme case \#1), at the bottom of the tree (extreme case \#2) or anywhere in between, which we discuss next.
			  
			  You should now be able to see more easily that, as long as xi≠xi′ but the computed root hashes are the same (i.e., zk+1\=zk+1′\=h), then there must exist some level j∈\[k\] where there is a collision:
			  
			  ∃ level j∈\[k\] s.t. {H(zj−1,hj−1)\=H(zj−1′,hj−1′), if bj−1\=1H(hj−1,zj−1)\=H(hj−1′,zj−1′), if bj−1\=0but with zj−1≠zj−1′ or hj−1≠hj−1′
			  
			  (Again, recall that z1\=xi and z1′\=xi′.) But such a collision at level j implies a break in the collision-resistance of H, which is a contradiction. QED.
			  
			  The claim about the existence of such a level j might not be easy to understand at first glance. It is best to draw yourself a Merkle proof together with the hashes computed during its verification and run through the following mental exercise: 
			  
			  Start at the root of the tree, at level k+1! Since both proofs verify and yield the same root hash, it could be that we either have a collision in H at this level or we don’t. If we do have a collision, we are done. If we do not, then we know that zk\=zk′ and hk\=hk′.
			  
			  Next, work your way down and continue on the subtree with root hash zk\=zk′. Again, it must be that either there was a collision or that zk−1\=zk−1′ and hk−1\=hk−1′. If there was a collision, we are done. Otherwise, we continue recursively.
			  
			  In the end, we will get to the bottom level which is guaranteed to have z1≠z1′ (because xi≠xi′) while z2\=z2′ from the previous level, which yields a collision. This is actually the _extreme case \#2_ that we’ve handled above! No matter what, there will always be a collision!
			  
			  \#\# Acknowledgments
			  
			  Special thanks to [Ittai Abraham](https://decentralizedthoughts.github.io/about-ittai/) for reviewing a draft of this post and sending insightful comments.
			  
			  \#\# References
			  
			  1. To be more specific, a Merkle tree **can be viewed as** a hash function on n inputs, but can be so much more than that. For example, when Merkle hashing a _dictionary_ with a large key space, a Merkle tree can be viewed as a hash function on 2256 inputs, where most of them are not set (i.e., “null”), which makes computing it (in a careful manner) feasible. Importantly, these kinds of Merkle trees allow for **non-membership** proofs of inputs that are set to null. [↩](\#fnref:consideredtobe)
			  2. Computational intractability would deserve its own post. For now, just think of it as _“no algorithm we can conceive of can break collision resistance **and** finish executing before the heat death of the Universe.”_ [↩](\#fnref:handwave)
			  3. [The First Blockchain or How to Time-Stamp a Digital Document](https://decentralizedthoughts.github.io/2020-07-05-the-first-blockchain-or-how-to-time-stamp-a-digital-document/) [↩](\#fnref:post1)
			  4. [Security proof for Nakamoto Consensus](https://decentralizedthoughts.github.io/2019-11-29-Analysis-Nakamoto/) [↩](\#fnref:post2)
			  5. For a simple explanation of Bitcoin’s block structure, see the author’s [presentation on Catena](https://alinush.github.io/talks.html\#catena-efficient-non-equivocation-via-bitcoin), \#shamelessplug. [↩](\#fnref:catena)
			  6. I’m assuming Dropbox is smart and doesn’t send a hash twice when it’s shared by two proofs. This is why the overhead is only b−1. <a href="\#fnref:dedup" class="reversefootnote" role="doc-backlink">↩</a></p> </li> <li id="fn:CW09" role="doc-endnote"> <p><strong>Efficient Data Structures for Tamper-Evident Logging</strong>, by Crosby, Scott A. and Wallach, Dan S., <em>in Proceedings of the 18th Conference on USENIX Security Symposium</em>, 2009&nbsp;<a href="\#fnref:CW09" class="reversefootnote" role="doc-backlink">↩</a></p> </li> <li id="fn:MBBplus15" role="doc-endnote"> <p><strong>CONIKS: Bringing Key Transparency to End Users</strong>, by Marcela S. Melara and Aaron Blankstein and Joseph Bonneau and Edward W. Felten and Michael J. Freedman, <em>in 24th USENIX Security Symposium (USENIX Security 15)</em>, 2015, <a href="https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/melara">\[URL\]</a>&nbsp;<a href="\#fnref:MBBplus15" class="reversefootnote" role="doc-backlink">↩</a></p> </li> <li id="fn:LK15" role="doc-endnote"> <p><strong>Revocation Transparency</strong>, by Ben Laurie and Emilia Kasper, 2015, <a href="https://www.links.org/files/RevocationTransparency.pdf">\[URL\]</a>&nbsp;<a href="\#fnref:LK15" class="reversefootnote" role="doc-backlink">↩</a></p> </li> <li id="fn:ELC16" role="doc-endnote"> <p><strong>Verifiable Data Structures</strong>, by Eijdenberg, Adam and Laurie, Ben and Cutter, Al, 2016, <a href="https://github.com/google/trillian/blob/master/docs/papers/VerifiableDataStructures.pdf">\[URL\]</a>&nbsp;<a href="\#fnref:ELC16" class="reversefootnote" role="doc-backlink">↩</a></p> </li> <li id="fn:contrast" role="doc-endnote"> <p>In contrast, the collision-resistant functions <span class="MathJax\_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-245-Frame" tabindex="0" style="position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>H</mi></math>" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-2513" style="width: 0.912em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.766em; height: 0px; font-size: 116%;"><span style="position: absolute; clip: rect(1.79em, 1000.77em, 2.73em, -1000em); top: -2.586em; left: 0em;"><span class="mrow" id="MathJax-Span-2514"><span class="mi" id="MathJax-Span-2515" style="font-family: STIXGeneral; font-style: italic;">H<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.047em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.586em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.056em; border-left: 0px solid; width: 0px; height: 0.869em;"></span></span></nobr><span class="MJX\_Assistive\_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>H</mi></math></span></span><script type="math/tex" id="MathJax-Element-245">H we discussed in our [previous post](https://decentralizedthoughts.github.io/2020-08-28-what-is-a-cryptographic-hash-function) take just one input x and hash it as h\=H(x). <a href="\#fnref:contrast" class="reversefootnote" role="doc-backlink">↩</a></p> </li> </ol> </div> </article> <div class="blog-tags"> Tags: <a href="/tags\#cryptography">cryptography</a> <a href="/tags\#merkle-hash-tree">merkle-hash-tree</a> <a href="/tags\#collision-resistant-hash-function">collision-resistant-hash-function</a> <a href="/tags\#integrity">integrity</a> </div> <!-- Check if any share-links are active --> <section id="social-share-section"> <span class="sr-only">Share: </span> <!--- Leave a comment on Twitter --> <a href="https://twitter.com/intent/tweet?text=What+is+a+Merkle+Tree%3F+https://decentralizedthoughts.github.io/2020-12-22-what-is-a-merkle-tree/" class="btn btn-social-icon btn-twitter" title="Leave a comment on Twitter"> <span class="fa fa-fw fa-twitter" aria-hidden="true"></span> <span class="sr-only">Twitter</span> </a> </section> <ul class="pager blog-pager"> <li class="previous"> <a href="/2020-12-12-raft-liveness-full-omission/" data-toggle="tooltip" data-placement="top" title="Raft does not Guarantee Liveness in the face of Network Faults">← Previous Post</a> </li> <li class="next"> <a href="/2021-02-28-good-case-latency-of-byzantine-broadcast-a-complete-categorization/" data-toggle="tooltip" data-placement="top" title="Good-case Latency of Byzantine Broadcast: a Complete Categorization">Next Post →</a> </li> </ul> <div class="disqus-comments"> </div> <div class="staticman-comments"> </div> <div class="justcomments-comments"> </div> </div> </div> </div> <footer> <div class="container beautiful-jekyll-footer"> <div class="row"> <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"> <ul class="list-inline text-center footer-links"><li><a href="https://twitter.com/ittaia" title="Twitter"><span class="fa-stack fa-lg" aria-hidden="true"> <i class="fa fa-circle fa-stack-2x"></i> <i class="fa fa-twitter fa-stack-1x fa-inverse"></i> </span> <span class="sr-only">Twitter</span> </a> </li></ul> <p class="copyright text-muted"> Decentralized Thinkers &nbsp;•&nbsp; 2023 </p> <!-- Please don't remove this, keep my open source work credited :) --> <p class="theme-by text-muted"> Theme by <a href="https://deanattali.com/beautiful-jekyll/">beautiful-jekyll</a> </p> </div> </div> </div> </footer> <!-- doing something a bit funky here because I want to be careful not to include JQuery twice! --> <script> if (typeof jQuery == 'undefined') { document.write('<script src="/js/jquery-1.11.2.min.js"></scr' + 'ipt>'); }
	- [Merkle Trees](https://omnivore.app/me/merkle-trees-18cfc289cef)
	  collapsed:: true
	  site:: [Omnivore](https://omnivore.app/tgrecojs/merkle-trees-18cfc251d0e)
	  date-saved:: [[01/12/2024]]
		- ### Content
		  collapsed:: true
			- January 12, 2024 • 7 min read
			  
			  Merkle Trees
			  
			  An efficient and verifiable data structure
			  
			  Merkle trees have become increasingly prevalent due to their key role in many decentralised systems. Although we are rarely exposed to them directly, they are worth studying for their elegance alone.
			  
			  \#\# Hash Functions
			  
			  A hash function is a mathematical function which maps anything (represented as a finite string of characters) into an output of fixed length. 
			  
			  This is tremendously useful. Any data has a signature that is significantly smaller than itself.
			  
			  ![hashing a string and an image example](https://proxy-prod.omnivore-image-cache.app/0x0,spSgTngAejCld5PFwb8k28su6seXV0GAKsPoAaDSeMFo/https://asselinpaul.com/img/merkle/hashing.png) 
			  
			  This signature can be used to verify the integrity of data downloaded from potentially dubious sources. Some sites will show the hash for files so that users can check whether the file has been tempered with.
			  
			  ![hashing an original versus a tempered version](https://proxy-prod.omnivore-image-cache.app/0x0,szpHB_wt6In68aZfnkVYnykhljgPg9fB0xQ_3XiUzLVc/https://asselinpaul.com/img/merkle/hashing2.png) 
			  
			  This highlights a key characteristic of hash functions. It must be _nearly_ impossible to modify a file to obtain a different file with the same hash (a hash collision).
			  
			  \#\#\# Properties of hash functions:
			  
			  * their input can be of any size
			  * their output is of fixed-size _e.g:_ 256-bit
			  * they are efficiently computable for an input of size _n_, its hash can be computed in _O(n)_ time
			  
			  \#\# Cryptographic Hash Functions
			  
			  Since Merkle trees are primarily used in settings where cryptography matters, our hash functions will have to abide by the following (stronger) properties:
			  
			  \#\#\# Collision Resistance
			  
			  A collision occurs when two distinct inputs produce the same output:
			  
			  ![example of a hash collision](https://proxy-prod.omnivore-image-cache.app/0x0,sYxeENI99j-1DR8jlwhjj4dZIyJPp-vPYLOVZPG-Vh7U/https://asselinpaul.com/img/merkle/collision.png) 
			  
			  A hash function is collision resistant if nobody can find a collision.
			  
			  It is worth noting that _"nobody can find"_ does not equate to _"does not exist"_. In fact, collisions do exist because the input space is larger than the output space. the input space is infinite whereas the output space is finite 
			  
			  This can be shown using the [pigeon-hole principle](https://en.wikipedia.org/wiki/Pigeonhole%5Fprinciple) , which states that if _n+1_ pigeons must inhabit _n_ pigeon-holes, at least one pigeon-hole must have more than one pigeon inhabitant.
			  
			  ![example of a hash collision](https://proxy-prod.omnivore-image-cache.app/0x0,scLtc4ma9jY61l1VpMmrzSirvrV-BfCZs1KYckKqCJnU/https://asselinpaul.com/img/merkle/io_space.png) 
			  
			  Using the pigeon-hole principle, we can formulate a process which is guaranteed to find a collision:
			  
			  Consider a hash function with a 256-bit output size. Pick 2256+1 distinct values and calculate their respective hashes. Since we picked more values than possible outputs, we are guaranteed that some pair collides when you apply the hash function.
			  
			  This method guarantees that we will cause a collision. We can reduce the number of values to examine while still being fairly likely to observe a collision by making use of the [birthday paradox](https://en.wikipedia.org/wiki/Birthday%5Fproblem) in a cryptographic setting (known as a [birthday attack](https://en.wikipedia.org/wiki/Birthday%5Fattack)). By examining the hashes of 2130+1 randomly chosen inputs, there is a 99.8 percent chance of finding a collision.
			  
			  This method of uncovering hash collisions works for every hash function but takes an impractical amount of time. It would likely take far longer than the age of the universe to find a collision using all the computing power available on earth. _Bitcoin and Cryptocurrency Technologies._ Princeton University Press, p.4
			  
			  For some hash functions, it it easy to produce collisions. Consider the following hash function:
			  
			  H(_x_) = _x_ mod 2256
			  
			  This function returns the last 256 bits of the input (a fixed-size output). It is trivial to find two values that have the same 256 bit ending. **5** and **5 + 2256** would cause a collision for example.
			  
			  We don't know whether such methods exist for other hash methods (_e.g_ [SHA512](https://en.wikipedia.org/wiki/SHA-2)). The general consensus is that these functions are suspected to be collision resistant but no formal proof has ever been made. The hash functions we rely on today have been tested thoroughly by mathematicians and no collision has been found. Occasionally, collisions are found after years of work and particular functions are phased out of cryptographic systems. such was the fate of [MD5](https://en.wikipedia.org/wiki/MD5)
			  
			  \#\#\# Hiding
			  
			  The second property our cryptographic hashes must abide by: given a hash output, it should be impossible to deduce its input.
			  
			  With **y = H(_x_)**, **_x_** can't be deduced from **y**.
			  
			  When the set of potential inputs is fairly restricted, this can be hard. Imagine a problem where you output _true_ or _false_. You then hash the result of the problem. An attacker can deduce whether the output was _true_ or _false_ by computing the hashes of those inputs on his own.
			  
			  In a sense, we want the hash input, **_x_** to be taken from a set that is very spread out. It turns out we can hide even an input that is not spread out by concatenating it with another input that is spread out.
			  
			  A hash function _H_ is said to be hiding if when a secret value _r_ is chosen from a probability distribution that has [_high min-entropy_](https://www.reddit.com/r/crypto/comments/4qwxdz/high%5Fminentropy/), then, given _H(r || x)_, it is infeasible to find x. where || denotes concatenation
			  
			  \#\#\# Puzzle Friendliness
			  
			  Lastly, we require hash functions to be puzzle friendly. This property is the least intuitive of the three.
			  
			  A hash function _H_ is said to be puzzle friendly if for ever every possible _n_\-bit output value, if _k_ is chosen from a distribution with high min-entropy, then it is infeasible to find _x_ such that _H(k || x)_ \= _y_ in time significantly less than 2n.
			  
			  In more concrete terms, if someone wants to have the hash function output **Z** and part of the input(**k**) has been chosen in a suitably random way, then it's very difficult to find the value **x** that makes the hash function output **Z**.
			  
			  \#\#\# An example: [SHA-256](https://en.wikipedia.org/wiki/SHA-2)
			  
			  Having examined the properties of cryptographic hash functions, let's take a look at a commonly used one: **[SHA-256](https://asselinpaul.com/SHA-256)**
			  
			  SHA-256 outputs 256-bit hashes and works by using the _Merkle-Damgård transform_ to convert the underlying fixed-length collision-resistant hash function the compression function into one that accepts arbitrary-length inputs.
			  
			  ![sha_256 diagram](https://proxy-prod.omnivore-image-cache.app/0x0,s9GPlXpfLn7hMwQYgluMR12gDL4y7hzLq-oOc9joSLpg/https://asselinpaul.com/img/merkle/sha_256.png) 
			  
			  The input is padded so that its length is a multiple of 512 bits. It can then be divided into the _n_ message block and processed as shown in the figure above.
			  
			  \#\#\# Recapitulative
			  
			  The hash serves as a fixed-length summary, or unambiguous signature, of a message. It gives us an efficient way to remember things we've seen before and to recognise them again. Whereas an entire file could have been hundreds-of-gigabytes in size, its hash is of fixed length (256 bits in our examples). This greatly reduces storage requirements and enables a great number of practical uses.
			  
			  It is worth noting that different applications of hash functions require varying properties. Although puzzle-friendliness might be required in cryptocurrency systems, it isn't for other applications.
			  
			  \#\# Hash Pointers
			  
			  ![hash pointer diagram](https://proxy-prod.omnivore-image-cache.app/0x0,sFI2GpinpepXqC5RXy9Sfh8vaoPAIB7z2xjwSwCtYYQI/https://asselinpaul.com/img/merkle/hash_pointer.png) 
			  
			  A Hash Pointer is a data-structure that points to data along with a cryptographic hash of the data. In addition to enabling information retrieval, hash pointers can be used to verify the integrity of the data.
			  
			  \#\# Block Chains
			  
			  ![blockchain diagram](https://proxy-prod.omnivore-image-cache.app/0x0,sfhTT81R7SiTcymb6FhD98Wri_vqmxKvWN06-v-EgbJc/https://asselinpaul.com/img/merkle/blockchain.png) 
			  
			  A block chain is a linked list that is built with hash pointers. It is a tamper-evident log because changes to the chain will cause detectable inconsistencies between a data block and the hash pointer to the data block (which cascades right through to the head pointer).
			  
			  ![blockchain cascading error diagram](https://proxy-prod.omnivore-image-cache.app/0x0,s5QiXMI3m1l0mdf4k6ZORhua0eXA47IZSR8iS1kby6DE/https://asselinpaul.com/img/merkle/blockchain2.png) 
			  
			  ![merkle tree diagram](https://proxy-prod.omnivore-image-cache.app/0x0,s1suFq6IGDmoMuCJNhzIa5aVXbSFYKjyyhtk-AtsIvLY/https://asselinpaul.com/img/merkle/merkle.png) 
			  
			  Ralph Merkle had the idea to combine binary trees and hash pointers to create the Merkle tree in 1979\. The leaves contain hash pointers (arranged in pairs) and the hash of each of these blocks is stored in the parent node.
			  
			  We only need to store the root of the tree to verify the integrity of the tree. As in the block chain example, a change at the leaf-level would induce a change to hashes that bubbles up all the way to the root node, effectively making the data-structure tamper-proof.
			  
			  The merkle tree improves over the block chain by enabling concise _proof of membership_. That is, it is efficient to figure out whether a data block is a member of the Merkle Tree.![](https://proxy-prod.omnivore-image-cache.app/0x0,sZbP1Yib1mky0uR-0Qc-nPy5_H6Xtuym1bsUKm0P1ViQ/https://asselinpaul.com/img/merkle/merkle_efficiency.png) Merkle tree efficiency in Bitcoin - [Source](http://chimera.labs.oreilly.com/books/1234000001802/ch07.html\#merkle%5Ftrees) 
			  
			  Proving that a data block is included in the tree only requires showing the blocks in the path from that data block to the root.
			  
			  ![merkle tree membership diagram](https://proxy-prod.omnivore-image-cache.app/0x0,sNSKnHUMCt-Ml8lxPAkXUA6hy3lX8lUt10P_M-7dlmOk/https://asselinpaul.com/img/merkle/membership.png) 
			  
			  If there are _n_ nodes in the tree, only about _log(n)_ items need to be shown. Even with large Merkle trees, we can prove membership in a relatively short time. The space and time requirements are of the order _log(n)_. whereas they are of the order _n_ for block chains 
			  
			  \#\#\# Git
			  
			  The version control system uses Merkle Trees to see which files changed in the tracked directory.
			  
			  ![git merkle](https://proxy-prod.omnivore-image-cache.app/0x0,sOn6gOiiwV75CypwawtBWMIUNF4JyZwyoArSFDE-fxv4/https://asselinpaul.com/img/merkle/git.png) [Source](https://www.slideshare.net/japh44/code-is-not-text-how-graph-technologies-can-help-us-to-understand-our-code-better) 
			  
			  \#\#\# Bitcoin
			  
			  Merkle Trees are used to summarise all the transactions in a particular block, thus providing an efficient way to verify whether a transaction is included in a block.
			  
			  \#\#\# Databases
			  
			  Apache Cassandra, Dynamo and other NoSQL databases use Merkle trees to detect inconsistencies between replicas of databases. [Source](https://wiki.apache.org/cassandra/AntiEntropy) 
			  
			  Merkle trees are very commonly used to achieve consensus in distributed systems (_e.g:_ [IPFS](https://ipfs.io/) uses a Merkle-DAG , [BitTorrent](https://en.wikipedia.org/wiki/BitTorrent), [dat](https://datproject.org/)) or to counter data degradation (_e.g:_ [ZFS](https://en.wikipedia.org/wiki/ZFS)).
			  
			  \#\# Further Reading
			  
			  * Traditional Merkle trees cannot be applied to graphs because graphs are more complicated than trees. This paper from Ashish Kundu IBM T J Watson Research Center and Elisa Bertino Department of Computer Science and CERIAS, Purdue University expands on the subject: [On Hashing Graphs](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.294.8694)
			  * [Merkle Tree Traversal in Log Space and Time](https://link.springer.com/chapter/10.1007/978-3-540-24676-3%5F32) by Michael Szydlo RSA Laboratories presents a technique to efficiently traverse Merkle trees.
			  * [The Swirlds Hashgraph Consensus Algorithm: Fair, Fast, Byzantine Fault Tolerance](http://www.swirlds.com/whitepapers/) by Leemon Baird presents a different hash graph data-structure.
			  
			  \#\#\# Thank you for your time.
			  
			  \#\#\# Sources
			  
			  \#\#\# Colophon
			  
			  Report issues with this page ->
	- [Merkle Trees](https://omnivore.app/me/merkle-trees-18cfc251d0e)
	  collapsed:: true
	  site:: [asselinpaul.com](https://asselinpaul.com/merkle.html)
	  labels:: [[logseq]] [[cryptography]] [[merkle-airdrop]]
	  date-saved:: [[01/12/2024]]
		- ### Content
		  collapsed:: true
			- An efficient and verifiable data structure
			  
			  Merkle trees have become increasingly prevalent due to their key role in many decentralised systems. Although we are rarely exposed to them directly, they are worth studying for their elegance alone.
			  
			  \#\# Hash Functions
			  
			  A hash function is a mathematical function which maps anything (represented as a finite string of characters) into an output of fixed length. 
			  
			  This is tremendously useful. Any data has a signature that is significantly smaller than itself.
			  
			  ![hashing a string and an image example](https://proxy-prod.omnivore-image-cache.app/0x0,spSgTngAejCld5PFwb8k28su6seXV0GAKsPoAaDSeMFo/https://asselinpaul.com/img/merkle/hashing.png) 
			  
			  This signature can be used to verify the integrity of data downloaded from potentially dubious sources. Some sites will show the hash for files so that users can check whether the file has been tempered with.
			  
			  ![hashing an original versus a tempered version](https://proxy-prod.omnivore-image-cache.app/0x0,szpHB_wt6In68aZfnkVYnykhljgPg9fB0xQ_3XiUzLVc/https://asselinpaul.com/img/merkle/hashing2.png) 
			  
			  This highlights a key characteristic of hash functions. It must be _nearly_ impossible to modify a file to obtain a different file with the same hash (a hash collision).
			  
			  \#\#\# Properties of hash functions:
			  
			  * their input can be of any size
			  * their output is of fixed-size _e.g:_ 256-bit
			  * they are efficiently computable for an input of size _n_, its hash can be computed in _O(n)_ time
			  
			  \#\# Cryptographic Hash Functions
			  
			  Since Merkle trees are primarily used in settings where cryptography matters, our hash functions will have to abide by the following (stronger) properties:
			  
			  \#\#\# Collision Resistance
			  
			  A collision occurs when two distinct inputs produce the same output:
			  
			  ![example of a hash collision](https://proxy-prod.omnivore-image-cache.app/0x0,sYxeENI99j-1DR8jlwhjj4dZIyJPp-vPYLOVZPG-Vh7U/https://asselinpaul.com/img/merkle/collision.png) 
			  
			  A hash function is collision resistant if nobody can find a collision.
			  
			  It is worth noting that _"nobody can find"_ does not equate to _"does not exist"_. In fact, collisions do exist because the input space is larger than the output space. the input space is infinite whereas the output space is finite 
			  
			  This can be shown using the [pigeon-hole principle](https://en.wikipedia.org/wiki/Pigeonhole%5Fprinciple) , which states that if _n+1_ pigeons must inhabit _n_ pigeon-holes, at least one pigeon-hole must have more than one pigeon inhabitant.
			  
			  ![example of a hash collision](https://proxy-prod.omnivore-image-cache.app/0x0,scLtc4ma9jY61l1VpMmrzSirvrV-BfCZs1KYckKqCJnU/https://asselinpaul.com/img/merkle/io_space.png) 
			  
			  Using the pigeon-hole principle, we can formulate a process which is guaranteed to find a collision:
			  
			  Consider a hash function with a 256-bit output size. Pick 2256+1 distinct values and calculate their respective hashes. Since we picked more values than possible outputs, we are guaranteed that some pair collides when you apply the hash function.
			  
			  This method guarantees that we will cause a collision. We can reduce the number of values to examine while still being fairly likely to observe a collision by making use of the [birthday paradox](https://en.wikipedia.org/wiki/Birthday%5Fproblem) in a cryptographic setting (known as a [birthday attack](https://en.wikipedia.org/wiki/Birthday%5Fattack)). By examining the hashes of 2130+1 randomly chosen inputs, there is a 99.8 percent chance of finding a collision.
			  
			  This method of uncovering hash collisions works for every hash function but takes an impractical amount of time. It would likely take far longer than the age of the universe to find a collision using all the computing power available on earth. _Bitcoin and Cryptocurrency Technologies._ Princeton University Press, p.4
			  
			  For some hash functions, it it easy to produce collisions. Consider the following hash function:
			  
			  H(_x_) = _x_ mod 2256
			  
			  This function returns the last 256 bits of the input (a fixed-size output). It is trivial to find two values that have the same 256 bit ending. **5** and **5 + 2256** would cause a collision for example.
			  
			  We don't know whether such methods exist for other hash methods (_e.g_ [SHA512](https://en.wikipedia.org/wiki/SHA-2)). The general consensus is that these functions are suspected to be collision resistant but no formal proof has ever been made. The hash functions we rely on today have been tested thoroughly by mathematicians and no collision has been found. Occasionally, collisions are found after years of work and particular functions are phased out of cryptographic systems. such was the fate of [MD5](https://en.wikipedia.org/wiki/MD5)
			  
			  \#\#\# Hiding
			  
			  The second property our cryptographic hashes must abide by: given a hash output, it should be impossible to deduce its input.
			  
			  With **y = H(_x_)**, **_x_** can't be deduced from **y**.
			  
			  When the set of potential inputs is fairly restricted, this can be hard. Imagine a problem where you output _true_ or _false_. You then hash the result of the problem. An attacker can deduce whether the output was _true_ or _false_ by computing the hashes of those inputs on his own.
			  
			  In a sense, we want the hash input, **_x_** to be taken from a set that is very spread out. It turns out we can hide even an input that is not spread out by concatenating it with another input that is spread out.
			  
			  A hash function _H_ is said to be hiding if when a secret value _r_ is chosen from a probability distribution that has [_high min-entropy_](https://www.reddit.com/r/crypto/comments/4qwxdz/high%5Fminentropy/), then, given _H(r || x)_, it is infeasible to find x. where || denotes concatenation
			  
			  \#\#\# Puzzle Friendliness
			  
			  Lastly, we require hash functions to be puzzle friendly. This property is the least intuitive of the three.
			  
			  A hash function _H_ is said to be puzzle friendly if for ever every possible _n_\-bit output value, if _k_ is chosen from a distribution with high min-entropy, then it is infeasible to find _x_ such that _H(k || x)_ \= _y_ in time significantly less than 2n.
			  
			  In more concrete terms, if someone wants to have the hash function output **Z** and part of the input(**k**) has been chosen in a suitably random way, then it's very difficult to find the value **x** that makes the hash function output **Z**.
			  
			  \#\#\# An example: [SHA-256](https://en.wikipedia.org/wiki/SHA-2)
			  
			  Having examined the properties of cryptographic hash functions, let's take a look at a commonly used one: **[SHA-256](https://asselinpaul.com/SHA-256)**
			  
			  SHA-256 outputs 256-bit hashes and works by using the _Merkle-Damgård transform_ to convert the underlying fixed-length collision-resistant hash function the compression function into one that accepts arbitrary-length inputs.
			  
			  ![sha_256 diagram](https://proxy-prod.omnivore-image-cache.app/0x0,s9GPlXpfLn7hMwQYgluMR12gDL4y7hzLq-oOc9joSLpg/https://asselinpaul.com/img/merkle/sha_256.png) 
			  
			  The input is padded so that its length is a multiple of 512 bits. It can then be divided into the _n_ message block and processed as shown in the figure above.
			  
			  \#\#\# Recapitulative
			  
			  The hash serves as a fixed-length summary, or unambiguous signature, of a message. It gives us an efficient way to remember things we've seen before and to recognise them again. Whereas an entire file could have been hundreds-of-gigabytes in size, its hash is of fixed length (256 bits in our examples). This greatly reduces storage requirements and enables a great number of practical uses.
			  
			  It is worth noting that different applications of hash functions require varying properties. Although puzzle-friendliness might be required in cryptocurrency systems, it isn't for other applications.
			  
			  \#\# Hash Pointers
			  
			  ![hash pointer diagram](https://proxy-prod.omnivore-image-cache.app/0x0,sFI2GpinpepXqC5RXy9Sfh8vaoPAIB7z2xjwSwCtYYQI/https://asselinpaul.com/img/merkle/hash_pointer.png) 
			  
			  A Hash Pointer is a data-structure that points to data along with a cryptographic hash of the data. In addition to enabling information retrieval, hash pointers can be used to verify the integrity of the data.
			  
			  \#\# Block Chains
			  
			  ![blockchain diagram](https://proxy-prod.omnivore-image-cache.app/0x0,sfhTT81R7SiTcymb6FhD98Wri_vqmxKvWN06-v-EgbJc/https://asselinpaul.com/img/merkle/blockchain.png) 
			  
			  A block chain is a linked list that is built with hash pointers. It is a tamper-evident log because changes to the chain will cause detectable inconsistencies between a data block and the hash pointer to the data block (which cascades right through to the head pointer).
			  
			  ![blockchain cascading error diagram](https://proxy-prod.omnivore-image-cache.app/0x0,s5QiXMI3m1l0mdf4k6ZORhua0eXA47IZSR8iS1kby6DE/https://asselinpaul.com/img/merkle/blockchain2.png) 
			  
			  ![merkle tree diagram](https://proxy-prod.omnivore-image-cache.app/0x0,s1suFq6IGDmoMuCJNhzIa5aVXbSFYKjyyhtk-AtsIvLY/https://asselinpaul.com/img/merkle/merkle.png) 
			  
			  Ralph Merkle had the idea to combine binary trees and hash pointers to create the Merkle tree in 1979\. The leaves contain hash pointers (arranged in pairs) and the hash of each of these blocks is stored in the parent node.
			  
			  We only need to store the root of the tree to verify the integrity of the tree. As in the block chain example, a change at the leaf-level would induce a change to hashes that bubbles up all the way to the root node, effectively making the data-structure tamper-proof.
			  
			  The merkle tree improves over the block chain by enabling concise _proof of membership_. That is, it is efficient to figure out whether a data block is a member of the Merkle Tree.![](https://proxy-prod.omnivore-image-cache.app/0x0,sZbP1Yib1mky0uR-0Qc-nPy5_H6Xtuym1bsUKm0P1ViQ/https://asselinpaul.com/img/merkle/merkle_efficiency.png) Merkle tree efficiency in Bitcoin - [Source](http://chimera.labs.oreilly.com/books/1234000001802/ch07.html\#merkle%5Ftrees) 
			  
			  Proving that a data block is included in the tree only requires showing the blocks in the path from that data block to the root.
			  
			  ![merkle tree membership diagram](https://proxy-prod.omnivore-image-cache.app/0x0,sNSKnHUMCt-Ml8lxPAkXUA6hy3lX8lUt10P_M-7dlmOk/https://asselinpaul.com/img/merkle/membership.png) 
			  
			  If there are _n_ nodes in the tree, only about _log(n)_ items need to be shown. Even with large Merkle trees, we can prove membership in a relatively short time. The space and time requirements are of the order _log(n)_. whereas they are of the order _n_ for block chains 
			  
			  \#\# Uses of Merkle Trees
			  
			  \#\#\# Git
			  
			  The version control system uses Merkle Trees to see which files changed in the tracked directory.
			  
			  ![git merkle](https://proxy-prod.omnivore-image-cache.app/0x0,sOn6gOiiwV75CypwawtBWMIUNF4JyZwyoArSFDE-fxv4/https://asselinpaul.com/img/merkle/git.png) [Source](https://www.slideshare.net/japh44/code-is-not-text-how-graph-technologies-can-help-us-to-understand-our-code-better) 
			  
			  \#\#\# Bitcoin
			  
			  Merkle Trees are used to summarise all the transactions in a particular block, thus providing an efficient way to verify whether a transaction is included in a block.
			  
			  \#\#\# Databases
			  
			  Apache Cassandra, Dynamo and other NoSQL databases use Merkle trees to detect inconsistencies between replicas of databases. [Source](https://wiki.apache.org/cassandra/AntiEntropy) 
			  
			  Merkle trees are very commonly used to achieve consensus in distributed systems (_e.g:_ [IPFS](https://ipfs.io/) uses a Merkle-DAG , [BitTorrent](https://en.wikipedia.org/wiki/BitTorrent), [dat](https://datproject.org/)) or to counter data degradation (_e.g:_ [ZFS](https://en.wikipedia.org/wiki/ZFS)).
			  
			  \#\# Further Reading
			  
			  * Traditional Merkle trees cannot be applied to graphs because graphs are more complicated than trees. This paper from Ashish Kundu IBM T J Watson Research Center and Elisa Bertino Department of Computer Science and CERIAS, Purdue University expands on the subject: [On Hashing Graphs](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.294.8694)
			  * [Merkle Tree Traversal in Log Space and Time](https://link.springer.com/chapter/10.1007/978-3-540-24676-3%5F32) by Michael Szydlo RSA Laboratories presents a technique to efficiently traverse Merkle trees.
			  * [The Swirlds Hashgraph Consensus Algorithm: Fair, Fast, Byzantine Fault Tolerance](http://www.swirlds.com/whitepapers/) by Leemon Baird presents a different hash graph data-structure.
			  
			  \#\#\# Thank you for your time.
			  
			  \#\#\# Sources
			  
			  \#\#\# Colophon
	- [How I take Notes: Mastering the Basics - by Nicola Ballotta](https://omnivore.app/me/how-i-take-notes-mastering-the-basics-by-nicola-ballotta-18cf594cd16)
	  collapsed:: true
	  site:: [The Hybrid Hacker](https://hybridhacker.email/p/how-i-take-notes-mastering-the-basics)
	  author:: Nicola Ballotta
	  labels:: [[logseq]] [[note-taking]] [[hybrid-hacker]] [[processes]]
	  date-saved:: [[01/10/2024]]
	  date-published:: [[03/09/2023]]
		- ### Content
		  collapsed:: true
			- \#\#\# A Practical Guide on How to Take Notes. In This First Part, We Will Explore the Basics of Note-taking.
			  
			  I'm honest, if I had to start this essay from a blank page, I'd probably spend hours looking at the blinking cursor without writing a single character. But luckily enough, I've been thinking about this post for weeks now, and guess what? I have all my notes about it, which made starting the piece much more straightforward.
			  
			  When I was younger, precisely in school, **I literally hated taking notes**. I know people who still love to show their school notebooks and diaries, full of notes, schemas, drawings, schedules, and writings. I also still have mine at my parents' house, and you could probably sell them as new.
			  
			  I was so arrogant as to pretend to record everything in my head. Well, I did that for a long time, and I was also good enough at it. But unfortunately, **our brain's capacity is limited** (approximately **2.5 Petabytes of storage** according [Scientific American](https://www.scientificamerican.com/article/what-is-the-memory-capacity/)), and so at one point, my brain started overflowing, losing information. This is when I started taking notes, and this is also where **my life changed**.
			  
			  Someone might think note-taking is just about recording informations, but it's not. I said note-taking literally changed my life, and it was not just a catchy phrase. If you ask yourself why you take notes, the first answers that will come to your mind would probably be "_**to not forget important things**_" or "_**to organize my knowledge**_". And for sure, **these are good reasons to take notes**, but there are also other aspects that probably are not so evident at first glance.
			  
			  Some of the benefits of note-taking, especially if done the right way, include:
			  
			  * 🧠 **Increased memory efficiency**. Writing is a very good way to impress things in your brain and exercise it.
			  * ✍️ **Become better at writing**. Taking notes means writing more, and the more you write, the better you become at it.
			  * 📖 **Become better at reading**. As for writing, reading is a huge part of note-taking.
			  * 🤓 **Improved understanding**. Writing notes means processing information (we will see after how) and processing information helps better understand concepts.
			  * 👮‍♂️ **Increased discipline**. As you may imagine, to be good at all the points I mentioned before, you need to be disciplined, and writing notes is a good way to become it!
			  
			  Another **common misconception is that** **taking structured notes is just for researchers or students**. Nothing could be further from the truth.
			  
			  Taking notes is simply for everyone. It's just a process, **a habit that you establish in your everyday routine** that helps process and keep track of any kind of information. It doesn't matter if you are tracking your research in neuroscience, your fitness progress, your mood, or your cooking recipes; it works the same way.
			  
			  [![](https://proxy-prod.omnivore-image-cache.app/1019x457,sDHjRo1Jy-zMfe6NryEmMkxpQiu5a441sU0nuQaQYknI/https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73d2d758-3490-40f8-a556-e5435efa4302_1019x457.png)](https://substackcdn.com/image/fetch/f%5Fauto,q%5Fauto:good,fl%5Fprogressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73d2d758-3490-40f8-a556-e5435efa4302%5F1019x457.png)
			  
			  There's **an input**, you decide if this input **is relevant** for you, if it is **you process it** and then you store it in a note. Easy peasy.
			  
			  \#\# 📚 A Bit of Theory
			  
			  When you start delving deep into note-taking, **you will discover an entirely new world**.
			  
			  There are entire books about note-taking, methodologies to organize your notes, to grow them, and at one point, to make them yours. It would probably take many issues of this newsletter to go through them all. For the scope of this essay, which is **to share the way I take notes** and **introduce you to this world**, I will just go through some concepts that you will see used in the more practical part.
			  
			  \#\#\# PKM vs PKD
			  
			  Note-taking refers to the action of recording information in a place of your choice, such as a notebook, text file, dedicated software, database, etc. However, it is often put in relation to **Personal Knowledge Management** (PKM).
			  
			  Personal Knowledge Management refers to the **process of** **collecting, organizing, and managing one's own personal knowledge** and information in a way that is useful and accessible.
			  
			  Some people also make a further distinction between Personal Knowledge Management and **Personal Knowledge Development** (PKD). While the former involves collecting and organizing notes, the latter refers to the **process of acquiring, organizing, and integrating new information and experiences into one's existing knowledge base**. It involves actively seeking out new information, reflecting on one's experiences, and making connections between new and old knowledge.
			  
			  \#\#\# P.A.R.A.
			  
			  The P.A.R.A. method is a note-taking and personal knowledge management system created by [Tiago Forte](https://fortelabs.com/), a productivity and organization expert.
			  
			  P.A.R.A. stands for **Projects**, **Areas**, **Resources**, and **Archives**, and the main idea is to organize your notes **based on their actionability**.
			  
			  * 📂 **Projects** \- This section is designated for your ongoing projects. A project refers to a series of tasks that are linked to a specific objective and must be completed within a **defined timeframe**. These tasks represent the **tangible actions** you intend or must undertake.
			  * 📍**Areas** \- This section contains **ongoing activities** that are **still actionable** but **do not have a fixed deadline**, such as work notes, writing, personal finance, and maintaining one's health. These are tasks that demand regular maintenance and attention. As these activities are consistently monitored, new projects may emerge from this section.
			  * ⛏️ **Resources** \- This section serves as a r**epository for information on topics that pique your interest** or prove valuable to you. As the title implies, these are nuggets of knowledge that you wish to retain and consult at a later time.
			  * 🗄️ **Archives** \- This section is designated for **storing items from the other three categories that have already been finished** or are no longer relevant. This includes items such as completed projects, inactive areas, or resources that you no longer wish to actively manage.
			  
			  [![](https://proxy-prod.omnivore-image-cache.app/1019x457,s2ypoZipZ0YGspNkXQD6U3Zvh4roiqo1_orv4pwksWRY/https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F67fa7065-82f3-47ee-adfc-3de16d299332_1019x457.png)](https://substackcdn.com/image/fetch/f%5Fauto,q%5Fauto:good,fl%5Fprogressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F67fa7065-82f3-47ee-adfc-3de16d299332%5F1019x457.png)
			  
			  According to Tiago Forte, **these are the four folders you should have** to organize your knowledge and where to put your notes.
			  
			  As you may have noticed, while the Projects and Archives sections are pretty clear sections, the **Area and Resources sections are less defined and could overlap**. Don't worry too much about this; these are just guidelines and inspirations. You can decide how to manage your knowledge!
			  
			  Personally, I use the Area folder for work-related notes, essays, etc. - things that regularly change and are more actionable. While I put most of the things I'm interested in (e.g. Technology, Cooking, Outdoor) in the Resources folder. You will find people who choose where to put things based on how personal they are and others who put just files, schemes, drawings in the Resource folder. **Do whatever you feel is right for you**.
			  
			  \#\#\# Zettelkasten
			  
			  Zettelkasten is **something in between a knowledge management and development system** that was ideated by German sociologist [Niklas Luhmann](https://en.wikipedia.org/wiki/Niklas%5FLuhmann). The name "Zettelkasten" means "slip box" or "index card system" in German, and it refers to a physical or digital collection of notes that are stored and organized in a specific way to aid in idea generation and knowledge organization.
			  
			  [![](https://proxy-prod.omnivore-image-cache.app/1019x457,s8SBE167FS-8exOGcVTi22tNLHeZwEmUOrXh8TdqPe4U/https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4e0dded0-9b30-4220-8f03-44f8f68ad820_1019x457.png)](https://substackcdn.com/image/fetch/f%5Fauto,q%5Fauto:good,fl%5Fprogressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4e0dded0-9b30-4220-8f03-44f8f68ad820%5F1019x457.png)
			  
			  In a Zettelkasten system, **each note is created on a separate card or digital file**, with a unique identifier, date, and title. The notes are then organized by topic or theme and **connected to other relevant notes through a system of links or tags**. The goal of this system is to allow for flexible and creative idea generation and organization, as well as to enable effective retrieval and synthesis of information.
			  
			  The Zettelkasten methodology has three fundamental concepts:
			  
			  * 📥 **Fleeting Notes** \- These are notes in their most primitive stage. Whenever something sparks your interest, an idea, or something you want to explore further, you should quickly take note of it. For example, "I see a relation between Availability and Accountability in remote working." This should be a **brief but meaningful note**. It's not important how you write it or if it contains typos. You can see it as a reminder that needs to be processed later.
			  * 📚 **Literature Notes** \- These notes are useful when you want to reference something that already exists, such as a theory, idea, or notion. Ideally, even if it's coming from an external source, **you should write this note in your own words**. However, some notes can be copy-pasted.
			  * 🍀 **Permanent Notes** \- This is one of the most important pieces of the Zettelkasten method. While Literature Notes are thoughts coming from third parties, **permanent notes** (also known as Evergreen Notes) **reflect your thoughts**. They could be influenced by Literature Notes, but they should always include your personal thoughts on a particular topic.
			  
			  For Zettelkasten, you should only have these three folders. However, finding notes could become difficult, so how can you find them effectively? In Zettelkasten, there are two more concepts that are crucial:
			  
			  * 🔗 **Links** \- As we saw before, the main idea is to take atomic notes that you can process and elaborate on. But these notes are not very useful alone. That's why linking is one of the core principles of Zettelkasten. Linking multiple notes together can make them much more powerful.
			  * 🏷️ **Tags** \- All your ideas and notes, following the Zettelkasten approach, are scattered in these three folders. That's why you should always use tags. Tags make it easy to find things.
			  
			  I know these are a lot of concepts all together. Please consider that there are entire books discussing Zettelkasten (see the resources section), so it's challenging to condense everything in this article. But let me provide a real example to help you understand better.
			  
			  \#\#\#\# 🪚 A Practical Example
			  
			  Let's take the idea I mentioned earlier. Let’s pretend that while thinking or reading something, I came up with the idea that _Availability and Accountability are related when we talk about remote working_.
			  
			  This is what I would do (I actually did that before writing “[Balancing Availability and Accountability in Remote Working](https://hybridhacker.email/p/balancing-availability-and-accountability)”):
			  
			  * 📥 I take a quick fleeting note about my idea. It should **be meaningful** so I can come back to it later and understand what I was thinking about.
			  * 📚 Meanwhile, I want to have a clearer idea of what Availability and Accountability are, so I start gathering information from the web (or reading a book, or watching videos), to better understand these concepts. When I have a better understanding, I **create a literature note for Accountability and one for Availability**, storing the information I got from third parties there. I also put meaningful tags so I can easily find these notes when needed.
			  * 🍀 After thinking more about my idea, I decide it's time to transform it into something permanent. So I create a permanent/evergreen note. This note **is written in my own words and reflects my idea**, even though I can link the literature notes I created earlier to help contextualize. I also tag this note so it's easier to find when I need it.
			  
			  You see the power of this approach? I hope so, because we are just scratching the surface!
			  
			  \#\# Resources
			  
			  The concepts I explained earlier should be sufficient to understand the basics and approach the more practical guide that we will explore in the next part of this essay. If you wish to dive deeper, here are some interesting resources you can read.
			  
			  📚 **Books**
			  
			  * [How to Take Smart Notes](https://www.amazon.com/How-Take-Smart-Notes-Technique-dp-3982438802/dp/3982438802/) (Sönke Ahrens) - Probably the best and most famous book about Zettelkasten method
			  * [Building a Second Brain](https://www.amazon.com/Building-Second-Brain-Organize-Potential/dp/1982167386) (Tiago Forte) - A must read for notes taking (includes the P.A.R.A method)
			  
			  🔗 **Links**
			  
			  * [Progressive Summarization](https://fortelabs.com/blog/progressive-summarization-a-practical-technique-for-designing-discoverable-notes/) \- How to write better and easily discoverable notes
			  * [Writing Atomic Notes](https://zettelkasten.de/posts/create-zettel-from-reading-notes/) \- Good and practical examples on how to take atomic notes and process them
			  
			  \#\#\#\# 🗣️ Other
			  
			  * <https://www.reddit.com/r/NoteTaking/> \- Subreddit where to exchange informations on how to take notes
			  * <https://www.reddit.com/r/Zettelkasten/> \- Subreddit dedicated to Zettelkasten methodology
			  
			  \#\# ⏩ What to Expect Next
			  
			  I know that all these concepts together, could seem intimidating, but they will be needed to understand the second and more practical part of my note-taking approach. In the next part of “How I take Notes” I will tell you:
			  
			  * How I process notes and transform them into meaningful knowledge
			  * How my PKM workflow works
			  * How I structured my PKM folders
			  * How I use Obsidian to manage my PKM applying the principles I described
			  
			  \#\# ✌️ That’s all folks
			  
			  That's all for today! As always, I would love to hear from my readers (and if you've made it this far, you're definitely one of the bravest). Please don't hesitate to connect with me on [LinkedIn](https://www.linkedin.com/in/nicolaballotta) and send a message. I always respond to everyone!
	- [Organize your Omnivore library with labels](https://omnivore.app/me/organize-your-omnivore-library-with-labels-18a026d6ea3)
	  collapsed:: true
	  site:: [Omnivore Blog](https://blog.omnivore.app/p/organize-your-omnivore-library-with)
	  author:: The Omnivore Team
	  date-saved:: [[08/17/2023]]
	  date-published:: [[04/17/2022]]
		- ### Content
		  collapsed:: true
			- Omnivore provides labels (also known as tags) to help you organize your library. Labels can be added to any saved read, and your library can be filtered based on labels. 
			  
			  On the web if you have a larger screen you can find the labels tool on the left side of the screen. 
			  
			  [ ![](https://proxy-prod.omnivore-image-cache.app/960x711,sd_iEqPoEHqI7WkOUFPZl1axCkvtYhw5KBmUIne0oSQ0/https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa4ec9f3c-baef-464b-8d3a-0b8a384874d3_960x711.gif) ](https://substackcdn.com/image/fetch/f%5Fauto,q%5Fauto:good,fl%5Fprogressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa4ec9f3c-baef-464b-8d3a-0b8a384874d3%5F960x711.gif) 
			  
			  Adding a label from the left menu 
			  
			  For a smaller screen you will find the labels button at the top of the page. 
			  
			  [ ![](https://proxy-prod.omnivore-image-cache.app/1456x1315,sdpGYdxa-cZ3SZWswOh__3ynxRP98SMiWWeOJz6juAzY/https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fb59fdeb0-d711-442e-a7c2-4508bedad515_1818x1642.png) ](https://substackcdn.com/image/fetch/f%5Fauto,q%5Fauto:good,fl%5Fprogressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fb59fdeb0-d711-442e-a7c2-4508bedad515%5F1818x1642.png) 
			  
			  Article Actions at the top of the Omnivore Reader for smaller screens 
			  
			  iOS users can long press on an item in the library or access the labels modal from the menu in the top right of the reader page. 
			  
			  [ ![](https://proxy-prod.omnivore-image-cache.app/470x0,sOUHLFwk4mORdkuStr6Jl719evRUX-XTauXEp85h4iL4/https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F6c99b6c9-7b78-41a8-84b1-a738e832308d_1182x2034.png) ](https://substackcdn.com/image/fetch/f%5Fauto,q%5Fauto:good,fl%5Fprogressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F6c99b6c9-7b78-41a8-84b1-a738e832308d%5F1182x2034.png) 
			  
			  Editing labels from the library view on iOS 
			  
			  \#\#  Label searches on iOS 
			  
			  On iOS you can use the label search modal to search for specific labels. This will create an OR search and return all links matching the assigned labels. 
			  
			  [ ![](https://proxy-prod.omnivore-image-cache.app/418x0,s3ZzvKJlkfrGLNHHjmS1HkMp6toHMoHzZXkpZaap0C84/https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fc6720208-7551-41cb-a86d-afc58bb160c9_1084x2006.png) ](https://substackcdn.com/image/fetch/f%5Fauto,q%5Fauto:good,fl%5Fprogressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fc6720208-7551-41cb-a86d-afc58bb160c9%5F1084x2006.png) 
			  
			  Using labels to filter your search 
			  
			  \#\#  Using Advanced Search to filter your library with labels 
			  
			  Omnivore's advanced search syntax supports searching for multiple labels using AND and OR clauses. You can also negate a label search to find pages that do not have a certain label. 
			  
			  Some examples: 
			  
			  * `label:Newsletter` finds all pages that have the label Newsletter
			  * `label:Cooking,Fitness` finds all your pages with either the Cooking or Fitness labels
			  * `label:Newsletter label:Surfing` finds all pages with both the Newsletter and Surfing labels
			  * l`abel:Coding -label:News` finds all pages with the Coding label that do not have the News label